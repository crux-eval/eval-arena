<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8" />   <!--It is necessary to use the UTF-8 encoding with plotly graphics to get e.g. negative signs to render correctly -->
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link
  rel="stylesheet"
  href="https://crux-eval.github.io/static/css/bulma.min.css"
>
</head>


<body>


<section class="section" style="margin:0; padding:0;">
<div class="container is-max-desktop">
<div class="columns is-centered has-text-centered">
<div class="column is-full">
    <h2 class="title is-3"> {{benchmark_id}} </h2>
    <h3> <a href="https://github.com/crux-eval/eval-arena">README and Code</a></h3>

    <div class="content has-text-justified" style="font-size: 120%;">

        <h2>Example level results</h2>
        <p>There are {{outputs['list_no_solve']|length}} examples not solved by any model.
            Solving some of these can be a good signal that your model is indeed better than leading models.  <br>
        {{outputs['list_no_solve']|join(', ')}}</p>

        <h2>Problems solved by 1 model only</h2>
        <p>{{outputs['table_one_solve']}}</p>


        <h2>Histogram of accuracies</h2>
        <p>{{outputs['table_histogram_accs']}}</p>


        <h2>Mininum elo to solve each problems</h2>
        <p>For a mediocre model A, problems only solvable by much better models can be significant. </p>
        <p>{{outputs['fig_min_elo_solve']}}</p>

        <h2>Problems solved by mediocre or worse models only</h2>
        <p>These examples are suspect, and might be worth an inspection. </p>
        <p>{{outputs['table_suspect']}}</p>
    </div>
</div>
</div>
</div>
</section>


</body>
</html>