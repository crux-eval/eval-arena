<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8" />   <!--It is necessary to use the UTF-8 encoding with plotly graphics to get e.g. negative signs to render correctly -->
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link
  rel="stylesheet"
  href="https://crux-eval.github.io/static/css/bulma.min.css"
>
</head>

<body>

<section class="section" style="margin:0; padding:0;">
<div class="container is-max-desktop">
<div class="columns is-centered has-text-centered">
<div class="column is-full">
    <h2 class="title is-3"> {{benchmark_id}} </h2>
    <h3> <a href="https://github.com/crux-eval/eval-arena">README and Code</a></h3>

    <div class="content has-text-justified" style="font-size: 120%;">

    <h2>Result table </h2>
      <p>We show 3 methods currently used for evaluating code models,
      raw accuracy used by benchmarks, average win-rate over all other models (used by <a href="https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard">BigCode</a>),
      and Elo (<a href="https://en.wikipedia.org/wiki/Bradley%E2%80%93Terry_model">Bradly-Terry coefficients</a> following <a href="https://chat.lmsys.org/">Chatbot Arena</a>).
      Average win-rate always have good correlation with ELO. 
      </p>
    <p>{{sections['result table']}}</p>

    <h2>p-values </h2>
    <p>The null hypothesis is that model A and B each have a 1/2 chance to win whenever they are different, ties are not used.
    The p-value is the chance under the null-hypothesis to get a difference as extreme as the one observed.
    Hover over each entry to display extra information. </p>
    <p>{{sections['p-values']}}</p>

    <h2>Typical delta needed to give good p-values </h2>
    <p>We can also find the typical p-value for typical difference in accuracy. Hoover to display the actual model pairs for each point.</p>
    <p>{{sections['delta vs. p-values']}}</p>

    <h2>Pairwise wins (including ties) </h2>
    <p>Following <a href="https://chat.lmsys.org/">Chatbot Arena</a>, this is the head-to-head comparisons between all pairs of models, reporting wins, and two types of ties.</p>
    <p>{{sections['pairwise wins (including ties)']}}</p>



    </div>
</div>
</div>
</div>
</section>


</body>
</html>