{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json, glob\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Any, Iterator, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from jinja2 import Template\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "\n",
    "import arena\n",
    "import report_model\n",
    "\n",
    "from signal_noise import signal_to_noise\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from jinja2 import Template\n",
    "\n",
    "import importlib\n",
    "importlib.reload(arena)\n",
    "\n",
    "class ReportArgs:\n",
    "    out_dir: str = \"gh-pages/\"\n",
    "    data: str = \"data/*.jsonl\"\n",
    "    recompute: bool = True # generate results for all data and summary line\n",
    "    write_summary: bool = True # use results in out_dir/tmp to generate the summary table\n",
    "    \n",
    "    max_diff: float = 0.1 # skip models that are more than max_diff in performance\n",
    "    sigma_thres: float = 5.0 # how many std to consider as not close\n",
    "    min_perf: float = 0.05 # too bad for inconlusion, including near 0 models does give some extreme results\n",
    "\n",
    "def run_arena(args: ReportArgs):\n",
    "    records = []\n",
    "    for fname in glob.glob(args.data):\n",
    "        with open(fname, 'rt') as f:\n",
    "            records.extend([json.loads(l) for l in f.readlines()])\n",
    "    eval_results = pd.DataFrame(records)\n",
    "    benchmarks = set(eval_results['benchmark_id'])\n",
    "    print(benchmarks)\n",
    "    return eval_results\n",
    "\n",
    "args = ReportArgs()\n",
    "results = run_arena(args)\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bid = \"gsm8k\"\n",
    "bid = \"lcb_codegen_v6\"\n",
    "bid = \"humaneval+\"\n",
    "bid = \"mbpp\"\n",
    "bid = \"mgsm_cot\"\n",
    "bid = \"math_cot\"\n",
    "bid = \"mmlu\"\n",
    "bid = \"human_eval_plus\"\n",
    "bid = \"math500_cot\"\n",
    "bid = \"mmlu_pro_cot\"\n",
    "bid = \"mbpp_vllm\"\n",
    "bid = \"cruxeval_output_cot\"\n",
    "bid = \"swebench-verified\"\n",
    "bid = \"CRUXEval-output-T0.8\"\n",
    "selected = results[(results[\"benchmark_id\"] == bid) & (~results[\"model\"].str.contains(\"_distill_\", case=False))].copy()\n",
    "args.max_diff = 0.1 \n",
    "importlib.reload(arena)\n",
    "arena_res: arena.ArenaResult = arena.summarize_benchmark(selected, args)\n",
    "display(arena_res)\n",
    "df_model = arena.model_table(selected)\n",
    "df_example = arena.example_table(selected, df_model)\n",
    "df_input = selected.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_example_vs_model(df_input, df_model, df_example, use_acc_as_position=False):\n",
    "    df = df_input[[\"model\", \"example_id\", \"pass1\", \"N\"]].merge(df_example[[\"example_id\", \"pass1_of_ex\"]], on=\"example_id\")\n",
    "    model_table = df_model[[\"model\", \"pass1\"]].rename(columns={\"pass1\": \"pass1_of_model\"})\n",
    "    df = df.merge(model_table, on=\"model\")\n",
    "    df.sort_values(by=[\"pass1_of_ex\", \"example_id\", \"pass1_of_model\", \"model\"], inplace=True)\n",
    "    if not use_acc_as_position:\n",
    "        yid, xid = \"example_id\", \"model\"\n",
    "    else:\n",
    "        yid, xid = \"example_id\", \"pass1_of_model\"\n",
    "\n",
    "    fig = px.scatter(df, y=yid, x=xid, color=\"pass1\",\n",
    "                     opacity=0.75,\n",
    "                     color_continuous_scale=[\"red\", \"yellow\", \"green\"],\n",
    "                     hover_data=[\"pass1\", \"pass1_of_ex\", \"pass1_of_model\", \"model\", \"example_id\", \"N\"])\n",
    "    fig.update_xaxes(autorange=\"reversed\")\n",
    "    fig.update_traces(marker={\"symbol\": \"square\"})\n",
    "    fig.update_layout(\n",
    "            width=900, height=1200,\n",
    "            xaxis = dict(side =\"top\"),\n",
    "        )\n",
    "    return fig\n",
    "\n",
    "fig = fig_example_vs_model(df_input, df_model, df_example, use_acc_as_position=True)\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(report_model)\n",
    "# fig = report_model.fig_marginals(df_input, df_model, df_example, xkey=\"rank_of_ex\")\n",
    "# display(fig)\n",
    "# display(arena_res.summary)\n",
    "fig = report_model.fig_cov_baseline(\"test\", arena_res.summary, arena_res.input_table)\n",
    "betas = report_model.show_betas(df_input, df_model, df_example)\n",
    "display(betas)\n",
    "df_betas = pd.DataFrame(betas)\n",
    "df_betas[\"norm\"] = df_betas[\"expected_std\"] / np.sqrt(len(df_example))\n",
    "fig.add_scatter(x=df_betas[\"mu\"], y=df_betas[\"norm\"])\n",
    "display(fig)\n",
    "\n",
    "display(px.scatter(df_betas, x=\"mu\", y=\"alpha+beta\"))\n",
    "\n",
    "fig = report_model.fig_marginals(df_input, df_model, df_example, xkey=\"rank\")\n",
    "display(fig)\n",
    "\n",
    "# fig = px.histogram(df_example, x=\"pass1_of_ex\")\n",
    "# display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_df(selected: pd.DataFrame):\n",
    "    marginals = selected.groupby([\"example_id\"]).agg({'pass1': 'mean'}).reset_index().sort_values(by=\"pass1\")\n",
    "    display(marginals)\n",
    "    m1 = marginals[\"pass1\"].to_numpy().copy()\n",
    "    def independent_var(p: np.ndarray, alpha=1) -> float:\n",
    "        \"\"\"\n",
    "        calculate the variance of two independent draws from p, X_i, Y_i ~ Bernoulli(p_i), I want E[(X_i - Y_i)**2]\n",
    "        \"\"\"\n",
    "        N = len(p)\n",
    "        assert np.all(p >= 0) and np.all(p <= 1)\n",
    "        return np.sqrt(1 / N * np.mean(p * (1 - p)))\n",
    "\n",
    "    df = pd.DataFrame({\"alpha\": np.logspace(-5, 5, 1000)})\n",
    "\n",
    "    df[\"p_mean\"] = df[\"alpha\"].map(lambda alpha: np.power(m1, alpha).mean())\n",
    "    df[\"vars\"] = df[\"alpha\"].map(lambda alpha: independent_var(np.power(m1, alpha)))\n",
    "    m2 = np.where((0 < m1) & (m1 < 1), 0.5, m1)\n",
    "    df[\"p_mean_const\"] = df[\"alpha\"].map(lambda alpha: np.power(m2, alpha).mean())\n",
    "    df[\"vars_const\"] = df[\"alpha\"].map(lambda alpha: independent_var(np.power(m2, alpha)))\n",
    "    return df\n",
    "\n",
    "example_means = selected.groupby([\"example_id\"]).agg({'pass1': 'mean'}).reset_index().sort_values(by=\"pass1\")\n",
    "# \n",
    "# fig = px.line(y=m1)\n",
    "m1 = example_means[\"pass1\"].to_numpy().copy()\n",
    "fig = go.Figure()\n",
    "for alpha in []:\n",
    "    fig.add_scatter(y=m1**alpha, mode=\"lines\", name=f'm*{alpha}')\n",
    "\n",
    "# Calculate which models are in top/bottom half based on overall performance\n",
    "model_means = selected.groupby([\"model\"]).agg({'pass1': 'mean'}).reset_index().sort_values(by=\"pass1\")\n",
    "display(model_means)\n",
    "nzs = np.sum(example_means[\"pass1\"] == 0)\n",
    "interval_size = 0.125\n",
    "for start in np.linspace(0, 1, 8):\n",
    "    models = model_means[(model_means[\"pass1\"] >= start) & (model_means[\"pass1\"] < start + interval_size)]\n",
    "    # display(models)\n",
    "    data_inside = selected[selected['model'].isin(models[\"model\"])]\n",
    "    if len(data_inside) == 0:\n",
    "        continue\n",
    "    data_means = data_inside.groupby([\"example_id\"]).agg({'pass1': 'mean'}).reset_index()\n",
    "    # display(data_means, model_means)\n",
    "    # Merge with original marginals to ensure same sorting\n",
    "    data_means_sorted = example_means[['example_id']].merge(data_means, on=\"example_id\", how=\"left\")\n",
    "    data_means_sorted = data_means_sorted.sort_values(\"pass1\")\n",
    "    # wsz = 1\n",
    "    # smoothed = data_means_sorted[\"pass1\"].rolling(window=1, center=True).mean()\n",
    "    smoothed = data_means_sorted[\"pass1\"]\n",
    "    mu = data_means_sorted[\"pass1\"].mean()\n",
    "    n = len(models)\n",
    "    fig.add_scatter(x=smoothed, y=np.arange(len(smoothed))/len(smoothed), name=f\"{start:.2f}-{start+interval_size:.2f} ({n=}, {mu=:.3f})\", mode='lines')\n",
    "\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    alpha = smoothed.mean() / (1 - nzs / len(smoothed)) \n",
    "    beta_param = 1 - alpha\n",
    "    from scipy.stats import beta\n",
    "    s = 1\n",
    "    cdf_values = beta.cdf(x, s*alpha, s*beta_param)\n",
    "    beta_mean = alpha * (1 - nzs / len(smoothed))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x, \n",
    "        y= nzs/len(smoothed) + cdf_values * (1 - nzs/len(smoothed)), \n",
    "        # y= cdf_values * (len(smoothed)), \n",
    "        mode='lines',\n",
    "        name=f'Beta({alpha:.2f}, {beta_param:.2f}) {beta_mean=:.3f}',\n",
    "        line=dict(dash='dash')\n",
    "    ))\n",
    "# Add the first 3 model curves to the plot\n",
    "# for i, (model_name, curve_data) in enumerate(list(model_curves.items())[:10]):\n",
    "#     fig.add_scatter(y=curve_data, name=model_name, mode='lines')\n",
    "fig.update_layout(title=bid)\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_means = selected.groupby([\"model\"]).agg({'pass1': 'mean'}).reset_index().sort_values(by=\"pass1\")\n",
    "# display(model_means)\n",
    "nzs = np.sum(example_means[\"pass1\"] == 0)\n",
    "\n",
    "bottom_models = model_means[:10][\"model\"]\n",
    "top_models = model_means[-10:][\"model\"]\n",
    "mid_models = model_means[-20:-10][\"model\"]\n",
    "\n",
    "\n",
    "def get_mean(models):\n",
    "    data_inside = selected[selected['model'].isin(models)]\n",
    "    data_means = data_inside.groupby([\"example_id\"]).agg({'pass1': 'mean'}).reset_index()\n",
    "    data_means_sorted = example_means[['example_id']].merge(data_means, on=\"example_id\", how=\"left\")\n",
    "    data_means_sorted = data_means_sorted.sort_values(\"pass1\")\n",
    "    return data_means_sorted, data_means_sorted[\"pass1\"].mean()\n",
    "\n",
    "data_means_bot, bot_mean = get_mean(bottom_models)\n",
    "data_means_top, top_mean  = get_mean(top_models)\n",
    "data_means_mid, mid_mean = get_mean(mid_models)\n",
    "\n",
    "\n",
    "# mid_mean = alpha * top_mean + (1-alpha) * bot_mean\n",
    "alpha = (mid_mean - bot_mean) / (top_mean - bot_mean)\n",
    "fig = go.Figure()\n",
    "cdf_bot = stats.ecdf(data_means_bot[\"pass1\"])\n",
    "cdf_top = stats.ecdf(data_means_top[\"pass1\"])\n",
    "fig.add_scatter(x=data_means_bot[\"pass1\"], name=\"bot\")\n",
    "x = np.linspace(0, 1, 1000)\n",
    "fig.add_scatter(x=x, y=len(data_means_top)*cdf_bot.cdf.evaluate(x), name=\"bot_cdf\")\n",
    "print(alpha)\n",
    "fig.add_scatter(x=x, y=beta.cdf(x, alpha, 1-alpha)*len(data_means_bot), name=\"mid_beta\")\n",
    "fig.add_scatter(x=data_means_top[\"pass1\"], name=\"top\")\n",
    "fig.add_scatter(x=data_means_mid[\"pass1\"], name=\"mid_empirical\")\n",
    "mid_paired = alpha*(data_means_top[\"pass1\"]) + (1-alpha)*(data_means_bot[\"pass1\"])\n",
    "mid_unpaired = alpha*(data_means_top[\"pass1\"].to_numpy()) + (1-alpha)*(data_means_bot[\"pass1\"].to_numpy())\n",
    "mid_paired = mid_paired.sort_values()\n",
    "fig.add_scatter(x=mid_unpaired, name=\"mid_unpaired\")\n",
    "fig.add_scatter(x=mid_paired, name=\"mid_paired\")\n",
    "\n",
    "# alpha = 0.5\n",
    "mid_cdf = alpha*(cdf_top.cdf.evaluate(x)) + (1-alpha)*(cdf_bot.cdf.evaluate(x))\n",
    "fig.add_scatter(x=x, y=len(data_means_top)*mid_cdf, name=\"mid_cdf\")\n",
    "print(cdf_bot.cdf.probabilities)\n",
    "def expectation_ecdf_from_steps(cdf, f):\n",
    "    probs = np.diff(np.concatenate(([0.0], cdf.quantiles)))\n",
    "    print(probs)\n",
    "    return np.sum(f(cdf.quantiles) * probs)\n",
    "\n",
    "evar = expectation_ecdf_from_steps(cdf_bot.cdf, lambda x: x*(1-x))\n",
    "print(evar, 0.25*0.75)\n",
    "\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=600,\n",
    "    title=bid\n",
    ")\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_cov_baseline(bmname: str, diffvsum: pd.DataFrame, dfmodel):\n",
    "    df = diffvsum\n",
    "    # df[\"is_close\"] = np.where(df[\"sum(A-B)\"].abs() < df[\"total\"] / 20, \"close\", \"not_close\")\n",
    "    df = df[df[\"accA\"] >= df[\"accB\"]]\n",
    "    df[\"is_close\"] = np.where(np.abs(df[\"accA\"] - df[\"accB\"]) / df[\"std(A-B)\"] <= 3, \"close: ≤3σ\", \"not close: >3σ\")\n",
    "    color_map = {\n",
    "        \"close: ≤3σ\": \"blue\",      # Bright red\n",
    "        \"not close: >3σ\": \"#CCCCCC\"     # Light gray\n",
    "    } \n",
    "    figs = px.scatter(df,\n",
    "                    x=np.maximum(df[\"accB\"], df[\"accA\"]), y=\"std(A-B)\",\n",
    "                    color=\"is_close\",\n",
    "                    color_discrete_map=color_map,\n",
    "                    custom_data=[\"model_a\", \"model_b\", \"sum(A!=B)\", \"sum(A-B)\", \"pvalue\", \"std(A-B)\", \"accA\", \"accB\", \"corr(A,B)\"])\n",
    "    figs.for_each_trace(lambda trace: trace.update(opacity=0.5) \n",
    "                   if trace.name == \"not close: >3σ\" else None)\n",
    "    \n",
    "    figs.update_traces(hovertemplate=\n",
    "        \"<br>\".join([\n",
    "        \"Model A: %{customdata[0]} (acc: %{customdata[6]:.1%})\",\n",
    "        \"Model B: %{customdata[1]} (acc: %{customdata[7]:.1%})\", \n",
    "        \"total A≠B: %{customdata[2]:.1f}\",\n",
    "        \"total A-B: %{customdata[3]:.1f}\", \n",
    "        \"std(A-B): %{customdata[5]:.2%}\", \n",
    "        \"p-value: %{customdata[4]:.3g}\",\n",
    "        \"corr(A,B): %{customdata[8]:.3g}\",\n",
    "        ])  + \"<extra></extra>\")\n",
    "\n",
    "    figs.update_traces(\n",
    "        marker=dict(\n",
    "            size=3,\n",
    "            opacity=0.5, \n",
    "        )\n",
    "    )\n",
    "\n",
    "    data_sz = diffvsum.iloc[0][\"total\"]\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    y = np.sqrt(x*(1-x) / data_sz)\n",
    "\n",
    "    figl = go.Figure()\n",
    "\n",
    "    figl.add_trace(go.Scatter(\n",
    "        x=x, y=y, name=\"σ(acc)\",\n",
    "        # hoverinfo=\"skip\",\n",
    "        line=dict(color=\"lightgreen\")\n",
    "    ))\n",
    "\n",
    "    figl.add_trace(go.Scatter(\n",
    "        x=x, y=np.sqrt(2)*y, name=\"sqrt(2) σ(acc)\",\n",
    "        # hoverinfo=\"skip\",\n",
    "        line=dict(color=\"darkgreen\")\n",
    "    ))\n",
    "\n",
    "    figl.add_trace(go.Scatter(\n",
    "        x=dfmodel[\"p_mean\"], y=dfmodel[\"vars\"],\n",
    "        # hoverinfo=\"skip\",\n",
    "        line=dict(color=\"red\"),\n",
    "        name=\"exp\"\n",
    "    ))\n",
    "    figl.add_trace(go.Scatter(\n",
    "        x=dfmodel[\"p_mean_const\"], y=dfmodel[\"vars_const\"],\n",
    "        # hoverinfo=\"skip\",\n",
    "        line=dict(color=\"pink\"),\n",
    "        name=\"vars_const\"\n",
    "    ))\n",
    "\n",
    "    fig = go.Figure(data=figl.data + figs.data)\n",
    "    fig.update_layout(\n",
    "        width=800, height=600, title=bmname,\n",
    "        xaxis_title=\"mean(acc(A), acc(B))\",\n",
    "        yaxis_title=\"σ(A-B)\"\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "display(summary)\n",
    "display(fig_cov_baseline(bid, summary, trend_df(selected)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_stats(s, f=2, percent=True):\n",
    "    return f\"{s['mean']:.2f}±{s['std']:.2f} | [{s['min']:.2f}--{s['max']:.2f}] | n={s['count']} \"\n",
    "\n",
    "def format_stats_badge(s):\n",
    "    s_percent = dict(s)\n",
    "    for st in [\"mean\", \"std\", \"min\", \"max\"]:\n",
    "        s_percent[st] = 100 * s[st]\n",
    "    summary = summary_stats(s_percent)\n",
    "    mean = 100*s[\"mean\"]\n",
    "    return f'<span title=\"{summary}\">{mean:.2f}</span>'\n",
    "\n",
    "def write_summary_table(summary_count: pd.DataFrame, output_path: Path):\n",
    "    summary_count = summary_count.sort_values(by='benchmark_id')\n",
    "\n",
    "    def link_detail(bid):\n",
    "        l1 = f\"\"\"by <a href=\"model_{bid}.html\">models </a> \"\"\"\n",
    "        l2 = f\"\"\"<a href=\"ex_{bid}.html\"> examples </a>\"\"\"\n",
    "        l3 = f\"\"\"<a href=\"ex_v_model_{bid}.html\"> data </a>\"\"\"\n",
    "        return l1 + '|' + l2 + '|' + l3\n",
    "    summary_count['link to details'] = summary_count['benchmark_id'].apply(link_detail)\n",
    "\n",
    "    def normalize(counts, includes):\n",
    "        percent = counts.copy(deep=True)\n",
    "        for c in includes:\n",
    "            percent[c] = percent[c] / percent['size']\n",
    "        return percent\n",
    "\n",
    "    includes_cols = ['benchmark_id', 'size',  'std(A-B)', 'corr_ab', 'p5_min', 'p5_max', 'no_solve', 'tau-', 'sig_noise','link to details']\n",
    "    percent_cols = ['p5_min', 'p5_max', 'no_solve', 'tau-']\n",
    "    summary_percent = normalize(summary_count, percent_cols)\n",
    "\n",
    "    display(summary_percent)\n",
    "    template_path = r\"templates/summary.html\"\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "        with open(template_path) as template_file:\n",
    "            j2_template = Template(template_file.read())\n",
    "            output_file.write(j2_template.render({\n",
    "                'count_table': summary_count[includes_cols].to_html(escape=False, index=False),\n",
    "                'percent_table': summary_percent[includes_cols].to_html(\n",
    "                    escape=False,\n",
    "                    index=False,\n",
    "                    formatters={\n",
    "                        \"std(A-B)\": lambda x: format_stats_badge(x),\n",
    "                        \"corr_ab\": lambda x: format_stats_badge(x),\n",
    "                        'p5_min': lambda x: f'{x*100:.2f}',\n",
    "                        'p5_max': lambda x: f'{x*100:.2f}',\n",
    "                        'min_dist': '{:.2}'.format,\n",
    "                        'no_solve': '{:.2}'.format,\n",
    "                        'tau-': '{:.2}'.format,\n",
    "                        'sig_noise': '{:.2f}'.format,\n",
    "                    }),\n",
    "            }))\n",
    "            \n",
    "def generate_summary(args: ReportArgs):\n",
    "    tmp_dir = Path(args.out_dir) / 'tmp'\n",
    "    os.makedirs(tmp_dir, exist_ok=True)\n",
    "    \n",
    "    if args.write_summary:\n",
    "        records = []\n",
    "        for fname in glob.glob(f'{tmp_dir}/summary-*.jsonl'):\n",
    "            with open(fname, 'rt') as f:\n",
    "                records.extend([json.loads(l) for l in f.readlines()])\n",
    "        print(records)\n",
    "        write_summary_table(pd.DataFrame(records), Path(args.out_dir) / 'index.html')\n",
    "\n",
    "generate_summary(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create a range of alpha values to explore\n",
    "alphas = [0.1, 0.3, 0.5]\n",
    "\n",
    "# Create x values for plotting\n",
    "x = np.linspace(0, 1, 1000)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for alpha in alphas:\n",
    "    # For beta(alpha, 1-alpha), we need alpha > 0 and 1-alpha > 0, so 0 < alpha < 1\n",
    "    if 0 < alpha < 1:\n",
    "        beta_param = 1 - alpha\n",
    "        # Calculate CDF\n",
    "        cdf_values = beta.pdf(x, alpha, beta_param)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, \n",
    "            y=cdf_values, \n",
    "            mode='lines',\n",
    "            name=f'Beta({alpha}, {beta_param:.1f})'\n",
    "        ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Cumulative Distribution Function of Beta(α, 1-α)',\n",
    "    xaxis_title='x',\n",
    "    yaxis_title='CDF(x)',\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in np.linspace(0, 1, 20):\n",
    "    beta_modelpred = beta(2*alpha+1, 2*(1-alpha)+1) / beta(alpha, (1-alpha))\n",
    "    var = alpha * (1-alpha)\n",
    "    print(beta_modelpred, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import beta\n",
    "def plot_betapdf(a=0.5, b=0.5):    \n",
    "    # Define the integrand\n",
    "    def integrand(x):\n",
    "        return x**(a-1) * (1-x)**(b-1) / beta(a, b)\n",
    "\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    return px.scatter(x=x, y=integrand(x))\n",
    "\n",
    "alpha = 0.3\n",
    "fig = plot_betapdf(a=1, b=4)\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import mean, var\n",
    "A = torch.randn([100, 30], dtype=torch.float64) > 0\n",
    "A = A.to(torch.float32)\n",
    "def var(A, dim=None):\n",
    "    return torch.var(A, dim=dim, unbiased=False)\n",
    "# print(A)\n",
    "print(f\"{var(A)=}\")\n",
    "print(f\"{var(A, dim=0)=}\")\n",
    "print(f\"{mean(A)=}\")\n",
    "print(f\"{mean(var(A, dim=0))=}\")\n",
    "print(f\"{var(mean(A, dim=0))=}\")\n",
    "\n",
    "\n",
    "from numpy import mean, var\n",
    "A = A.numpy()\n",
    "print(f\"{var(A)=}\")\n",
    "print(f\"{var(var(A, axis=0))=}\")\n",
    "# print(f\"{var(A, axis=0)=}\")\n",
    "# print(f\"{mean(A)=}\")\n",
    "print(f\"{mean(var(A, axis=0))=}\")\n",
    "print(f\"{var(mean(A, axis=0))=}\")\n",
    "print(f\"{mean(var(A, axis=1))=}\")\n",
    "print(f\"{var(mean(A, axis=1))=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = []\n",
    "N = 100\n",
    "K = 2\n",
    "import numpy as np\n",
    "from numpy import mean, var, std\n",
    "\n",
    "def cov(A, B, ddof=0):\n",
    "    # okay, is there ever a time to need ddof=1?\n",
    "    return np.cov(A, B, ddof=ddof)[0, 1]\n",
    "\n",
    "class Paired:\n",
    "    @staticmethod\n",
    "    def sample_vars(A: np.ndarray, B: np.ndarray, dof=0) -> dict:\n",
    "        assert A.shape[0] == B.shape[0], \"should be paired\" \n",
    "        return {\n",
    "            \"var(E(A-B))\": var(mean(A-B, axis=1)),\n",
    "            \"E(var(A-B))\": mean(var(A, axis=1) + var(B, axis=1)),\n",
    "            \"var(A-B)\": var(A) + var(B) - 2 * cov(mean(A, axis=1), mean(B, axis=1)),\n",
    "            \"cov(A,B)\": cov(mean(A, axis=1), mean(B, axis=1)),\n",
    "            \"var(A) + var(B)\": var(A) + var(B),\n",
    "            # \"_var(A-B)\": mean(A**2 + B**2) - 2 * mean(mean(A, axis=1) * mean(B, axis=1)) - mean(A-B)**2,\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def sample_vars_unbiased(A: np.ndarray, B: np.ndarray, dof=0) -> dict:\n",
    "        assert A.shape[0] == B.shape[0] # paired data\n",
    "        kA = A.shape[1]\n",
    "        kB = A.shape[1]\n",
    "        return {\n",
    "            \"var(E(A-B))\": var(mean(A-B, axis=1)) - mean(var(A, axis=1)/(kA-1) + var(B, axis=1)/(kA-1)) ,\n",
    "            \"E(var(A-B))\": mean(var(A, axis=1)* (1 + 1/(kA-1)) + var(B, axis=1) * (1 + 1/(kB-1))),\n",
    "            \"var(A-B)\": var(A) + var(B) - 2 * cov(mean(A, axis=1), mean(B, axis=1)), # actually this is slightly biased too, but we ignore it\n",
    "            # \"_var(A-B)\": mean(A**2 + B**2) - 2 * mean(mean(A, axis=1) * mean(B, axis=1)) - mean(A-B)**2,\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def bernoulli_sample_vars(A: np.ndarray, B: np.ndarray, dof=0) -> dict:\n",
    "        ...\n",
    "\n",
    "    @staticmethod\n",
    "    def bernoulli_p_vars(pA: np.ndarray, pB: np.ndarray) -> dict:\n",
    "        assert pA.shape[0] == pB.shape[0]\n",
    "        assert pA.shape[1] == pB.shape[1] == 1\n",
    "        pA = pA.flatten()\n",
    "        pB = pB.flatten()\n",
    "        return {\n",
    "            \"var(E(A-B))\": var(pA - pB),\n",
    "            \"E(var(A-B))\": mean(pA*(1-pA) + pB*(1-pB)),\n",
    "            \"var(A-B)\": mean(pA)*(1-mean(pA)) + mean(pB)*(1-mean(pB)) - 2*cov(pA, pB),\n",
    "            \"cov(A,B)\": cov(pA, pB),\n",
    "            \"var(A) + var(B)\": mean(pA)*(1-mean(pA)) + mean(pB)*(1-mean(pB)),\n",
    "            \"_var(A-B)\": mean(pA + pB - 2*pA*pB) - mean(pA - pB)**2,\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def bernoulli_self(ph: np.ndarray, K: np.ndarray) -> dict:\n",
    "        ph = ph.flatten()\n",
    "        pB = ph\n",
    "        mu = mean(ph)\n",
    "        covAA = mean((ph*ph - 1/K*ph)*(1+1/(K-1)))  - mu * mu\n",
    "        return {\n",
    "            \"var(E(A-B))\": var(ph - pB),\n",
    "            \"E(var(A-B))\": mean(ph*(1-ph) + pB*(1-pB)),\n",
    "            \"var(A-B)\": mean(ph)*(1-mean(ph)) + mean(pB)*(1-mean(pB)) - 2*covAA,\n",
    "            \"cov(A,B)\": covAA,\n",
    "            \"var(A) + var(B)\": mean(ph)*(1-mean(ph)) + mean(pB)*(1-mean(pB)),\n",
    "            \"_var(A-B)\": mean(ph + pB - 2*ph*pB) - mean(ph - pB)**2,\n",
    "        }\n",
    "\n",
    "\n",
    "pA = np.random.rand(N, 1)\n",
    "pB = (pA + 1*(np.random.rand(N, 1)-0.5)).clip(0, 1)\n",
    "pA = pB\n",
    "for i in range(100):\n",
    "    A = np.random.rand(N, K)\n",
    "    A = np.where(A < pA, 1, 0)\n",
    "\n",
    "    B = np.random.rand(N, K)\n",
    "    B = np.where(B < pB, 1, 0)\n",
    "\n",
    "    delta = (A-B).mean() \n",
    "    vars = {\n",
    "        \"E(A-B)\": delta,\n",
    "        # \"var(A-B)\":  np.mean(np.mean(A*A + B*B, axis=1) - 2 * A.mean(axis=1) * B.mean(axis=1)) - delta * delta,\n",
    "        # \"var(A-B)\": mean(A*A + B*B) - 2*mean(mean(A, axis=1) * mean(B, axis=1)) - delta * delta,\n",
    "        \n",
    "    }\n",
    "    def total_variance_test(v: dict):\n",
    "        assert np.allclose(v[\"var(A-B)\"], v[\"E(var(A-B))\"] + v[\"var(E(A-B))\"]), v\n",
    "\n",
    "    def relative_error(v1, v2):\n",
    "        # for k in \"var(A-B)\", \"E(var(A-B))\", \"var(E(A-B))\"\n",
    "        ... \n",
    "\n",
    "    v = Paired.sample_vars(A, B)\n",
    "    total_variance_test(v) \n",
    "\n",
    "    vstar = Paired.bernoulli_p_vars(pA, pB)\n",
    "    total_variance_test(vstar)\n",
    "\n",
    "    B = np.random.rand(N, K)\n",
    "    pA_hat = A.mean(axis=1, keepdims=True)\n",
    "    B = np.where(B < pA, 1, 0)\n",
    "\n",
    "    pA_hat = A.mean(axis=1, keepdims=True)\n",
    "    C = np.random.rand(N, K)\n",
    "    C = np.where(C < pA, 1, 0)\n",
    "    vresamp = Paired.bernoulli_self(A.mean(axis=1, keepdims=True), K)\n",
    "    vresamp2 = Paired.bernoulli_p_vars(A.mean(axis=1, keepdims=True), A.mean(axis=1, keepdims=True))\n",
    "    # total_variance_test(vresamp)\n",
    "    \n",
    "    # v_unb = Paired.sample_vars_unbiased(A, A)\n",
    "    # total_variance_test(v_unb) \n",
    "\n",
    "    res.append({\n",
    "        **{(\"star\", k): v for k, v in vstar.items() if k==\"var(A-B)\"},\n",
    "        **{(\"resamp\", k): v for k, v in vresamp.items() if k==\"var(A-B)\"},\n",
    "        **{(\"resamp2\", k): v for k, v in vresamp2.items() if k==\"var(A-B)\"},\n",
    "        **{(\"hat\", k): v for k, v in v.items() if k==\"var(A-B)\"},\n",
    "        # **{(\"unb\", k): v for k, v in v_unb.items()},\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(res)\n",
    "# df[\"diff\"] = df[\"var(A-B)\"] - df[\"E(var(A-B))\"] - df[\"var(E(A-B))\"]\n",
    "# df[\"diff2\"] = df[\"_var(A-B)\"] - df[\"E(var(A-B))\"] - df[\"var(E(A-B))\"]\n",
    "# df[\"diff_star\"] = df[\"var(A-B)_star\"] - df[\"E(var(A-B))_star\"] - df[\"var(E(A-B))_star\"]\n",
    "# px.scatter(df, x=\"x\", y=\"y\"\n",
    "display(df.describe())\n",
    "df[\"diff\"] = df[(\"resamp\", \"var(A-B)\")] / df[(\"star\", \"var(A-B)\")] - 1\n",
    "df[\"diff2\"] = df[(\"resamp2\", \"var(A-B)\")] / df[(\"star\", \"var(A-B)\")] - 1\n",
    "df[\"diff3\"] = df[(\"hat\", \"var(A-B)\")] / df[(\"star\", \"var(A-B)\")] - 1\n",
    "display(df)\n",
    "display(df.describe())\n",
    "\n",
    "def rmse(diff):\n",
    "    return np.sqrt(np.mean(diff**2))\n",
    "\n",
    "print(\"MSE\", rmse(df[\"diff\"].to_numpy()))\n",
    "print(\"MSE2\", rmse(df[\"diff2\"].to_numpy()))\n",
    "print(\"MSE3\", rmse(df[\"diff3\"].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Single:\n",
    "    @staticmethod\n",
    "    def sample_vars(A: np.ndarray, dof=0) -> dict:\n",
    "        return {\n",
    "            \"var(E(A))\": var(mean(A, axis=1)),\n",
    "            \"E(var(A))\": mean(var(A, axis=1)),\n",
    "            \"var(A)\": var(A),\n",
    "        } \n",
    "    \n",
    "    @staticmethod\n",
    "    def sample_vars_unbiased2(A: np.ndarray) -> dict:\n",
    "        kA = A.shape[1]\n",
    "        N = A.shape[0]\n",
    "        return {\n",
    "            \"var(E(A))\": var(mean(A, axis=1)) - 1/(kA-1) * mean(var(A, axis=1)) + var(A)*1/(N*kA - 1), \n",
    "            \"E(var(A))\": mean(var(A, axis=1, ddof=1)), \n",
    "            \"var(A)\": var(A, ddof=1),  # empirically maybe still < 1% too large  \n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def sample_vars_unbiased(A: np.ndarray) -> dict:\n",
    "        kA = A.shape[1]\n",
    "        N = A.shape[0]\n",
    "        return {\n",
    "            \"var(E(A))\": var(mean(A, axis=1)) - 1/(kA-1) * mean(var(A, axis=1)) + var(A)*1/(N*kA - 1), \n",
    "            \"E(var(A))\": mean(var(A, axis=1)) * (1 + 1/(kA-1)), \n",
    "            \"var(A)\": var(A) * (1 + 1/(N*kA - 1)), # empirically maybe still < 1% too large \n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def bootstrap_SE(A: np.ndarray, boots_size=100) -> dict:\n",
    "        kA = A.shape[1]\n",
    "        N = A.shape[0]\n",
    "        means = []\n",
    "        for _ in range(boots_size):\n",
    "            inds = np.random.choice(N*kA, size=N, replace=True)\n",
    "            samples = A.flatten()[inds]\n",
    "            means.append(samples.mean())\n",
    "\n",
    "        SE = np.std(means)\n",
    "        return {\n",
    "            \"var(A)\": SE**2*N\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def bernoulli_p_vars(pA: np.ndarray) -> dict:\n",
    "        return {\n",
    "            \"var(E(A))\": var(pA),\n",
    "            \"E(var(A))\": mean(pA*(1-pA)),\n",
    "            \"var(A)\": mean(pA)*(1-mean(pA))\n",
    "        }\n",
    "    \n",
    "N, K = 1000, 10\n",
    "ph = np.random.rand(N, 1)\n",
    "# pA = 0.5 * np.ones((N, 1))\n",
    "# pA[:N//2] = 0\n",
    "res = []\n",
    "for i in range(1000):\n",
    "    A = np.random.rand(N, K)\n",
    "    A = np.where(A < ph, 1, 0)\n",
    "    # A = pA + 0.5 * np.random.randn(N, K)\n",
    "\n",
    "    def total_variance_test(v: dict):\n",
    "        assert np.isclose(v[\"var(A)\"], v[\"E(var(A))\"] + v[\"var(E(A))\"]), v\n",
    "\n",
    "    def relative_error(v1, v2):\n",
    "        # for k in \"var(A-B)\", \"E(var(A-B))\", \"var(E(A-B))\"\n",
    "        ... \n",
    "\n",
    "    v = Single.sample_vars(A)\n",
    "    total_variance_test(v) \n",
    "\n",
    "    vstar = Single.bernoulli_p_vars(ph)\n",
    "    total_variance_test(vstar)\n",
    "\n",
    "    v_unb = Single.sample_vars_unbiased(A)\n",
    "    # total_variance_test(v_unb)\n",
    "\n",
    "    v_unb2 = Single.sample_vars_unbiased2(A)\n",
    "    total_variance_test(v_unb2)\n",
    "    for k in v_unb:\n",
    "        assert np.isclose(v_unb[k], v_unb2[k])\n",
    "\n",
    "    se_boots = Single.bootstrap_SE(A, 10)\n",
    "\n",
    "    res.append({\n",
    "        # **{(\"star\", k): v for k, v in vstar.items()},\n",
    "        **{(\"hat\", k): (v - vstar[k]) / vstar[k] for k, v in v.items()},\n",
    "        **{(\"unb\", k): (v - vstar[k]) / vstar[k] for k, v in v_unb.items()},\n",
    "        **{(\"boots\", k): (v - vstar[k]) / vstar[k] for k, v in se_boots.items()},\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(res)\n",
    "# df[\"diff\"] = df[\"var(A-B)\"] - df[\"E(var(A-B))\"] - df[\"var(E(A-B))\"]\n",
    "# df[\"diff2\"] = df[\"_var(A-B)\"] - df[\"E(var(A-B))\"] - df[\"var(E(A-B))\"]\n",
    "# df[\"diff_star\"] = df[\"var(A-B)_star\"] - df[\"E(var(A-B))_star\"] - df[\"var(E(A-B))_star\"]\n",
    "display(df.aggregate(lambda x:\n",
    "    pd.Series({\n",
    "        \"std\": std(x),\n",
    "        \"mse\": np.sqrt(np.mean(x*x)),\n",
    "        \"mean\": np.mean(x),\n",
    "})))\n",
    "# px.scatter(df, x=\"x\", y=\"y\")\n",
    "display(df.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codegen_240613_loc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
