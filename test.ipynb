{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, math, glob\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from arena import result_table, pass1_to_battle \n",
    "\n",
    "records = []\n",
    "for fname in glob.glob(f\"data/*.jsonl\"):\n",
    "    with open(fname, 'rt') as f:\n",
    "        records.extend([json.loads(l) for l in f.readlines()])\n",
    "\n",
    "eval_results = pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>pass1</th>\n",
       "      <th>win_rate</th>\n",
       "      <th>elo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>0.774390</td>\n",
       "      <td>0.252795</td>\n",
       "      <td>1074.682237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>deepseek-coder-33b-instruct</td>\n",
       "      <td>0.762195</td>\n",
       "      <td>0.241489</td>\n",
       "      <td>1070.180987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>opencodeinterpreter-ds-33b</td>\n",
       "      <td>0.743902</td>\n",
       "      <td>0.238313</td>\n",
       "      <td>1063.469311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mixtral-8x22b-instruct-v0.1</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.233740</td>\n",
       "      <td>1061.242032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>speechless-codellama-34b</td>\n",
       "      <td>0.725610</td>\n",
       "      <td>0.219893</td>\n",
       "      <td>1056.801266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HuggingFaceH4--starchat2-15b-v0.1</td>\n",
       "      <td>0.719512</td>\n",
       "      <td>0.219258</td>\n",
       "      <td>1054.587410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>code-millenials-34b</td>\n",
       "      <td>0.719512</td>\n",
       "      <td>0.222815</td>\n",
       "      <td>1054.587410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>deepseek-coder-6.7b-instruct</td>\n",
       "      <td>0.719512</td>\n",
       "      <td>0.232342</td>\n",
       "      <td>1054.587410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>meta-llama-3-70b-instruct</td>\n",
       "      <td>0.719512</td>\n",
       "      <td>0.219385</td>\n",
       "      <td>1054.587410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>deepseek-coder-7b-instruct-v1.5</td>\n",
       "      <td>0.713415</td>\n",
       "      <td>0.216336</td>\n",
       "      <td>1052.377664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>1050.171848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>opencodeinterpreter-ds-6.7b</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.213796</td>\n",
       "      <td>1050.171848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>xwincoder-34b</td>\n",
       "      <td>0.701220</td>\n",
       "      <td>0.212398</td>\n",
       "      <td>1047.969787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>0.689024</td>\n",
       "      <td>0.205030</td>\n",
       "      <td>1043.576224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>openchat</td>\n",
       "      <td>0.689024</td>\n",
       "      <td>0.205030</td>\n",
       "      <td>1043.576224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>speechless-coder-ds-6.7b</td>\n",
       "      <td>0.664634</td>\n",
       "      <td>0.179116</td>\n",
       "      <td>1034.826534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>code-llama-70b-instruct</td>\n",
       "      <td>0.664634</td>\n",
       "      <td>0.195884</td>\n",
       "      <td>1034.826534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>white-rabbit-neo-33b-v1</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.190168</td>\n",
       "      <td>1032.645924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>codebooga-34b</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.176829</td>\n",
       "      <td>1032.645924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>claude-3-sonnet-20240229</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>1028.291714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mistral-large-latest</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.180767</td>\n",
       "      <td>1023.945755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>speechless-starcoder2-15b</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.167937</td>\n",
       "      <td>1023.945755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>deepseek-coder-1.3b-instruct</td>\n",
       "      <td>0.615854</td>\n",
       "      <td>0.162348</td>\n",
       "      <td>1017.439446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bigcode--starcoder2-15b-instruct-v0.1</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.157774</td>\n",
       "      <td>1015.273398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen--Qwen1.5-72B-Chat</td>\n",
       "      <td>0.597561</td>\n",
       "      <td>0.158283</td>\n",
       "      <td>1010.944426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>microsoft--Phi-3-mini-4k-instruct</td>\n",
       "      <td>0.597561</td>\n",
       "      <td>0.160315</td>\n",
       "      <td>1010.944426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>code-13b</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.131479</td>\n",
       "      <td>989.320717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>codegemma-7b-it</td>\n",
       "      <td>0.530488</td>\n",
       "      <td>0.116997</td>\n",
       "      <td>987.156507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>speechless-coding-7b-16k-tora</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.121570</td>\n",
       "      <td>984.991329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>speechless-starcoder2-7b</td>\n",
       "      <td>0.518293</td>\n",
       "      <td>0.118140</td>\n",
       "      <td>982.825021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>wizardcoder-15b</td>\n",
       "      <td>0.506098</td>\n",
       "      <td>0.110137</td>\n",
       "      <td>978.488381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>open-hermes-2.5-code-290k-13b</td>\n",
       "      <td>0.506098</td>\n",
       "      <td>0.108486</td>\n",
       "      <td>978.488381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>code-33b</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.118140</td>\n",
       "      <td>976.317727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>phi-2</td>\n",
       "      <td>0.457317</td>\n",
       "      <td>0.106199</td>\n",
       "      <td>961.064405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>wizardcoder-7b</td>\n",
       "      <td>0.457317</td>\n",
       "      <td>0.097180</td>\n",
       "      <td>961.064405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>code-llama-multi-34b</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.087779</td>\n",
       "      <td>954.486703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>deepseek-coder-33b</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.105818</td>\n",
       "      <td>954.486703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mistral-7b-codealpaca</td>\n",
       "      <td>0.432927</td>\n",
       "      <td>0.094639</td>\n",
       "      <td>952.287490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>starcoder2-15b-oci</td>\n",
       "      <td>0.432927</td>\n",
       "      <td>0.088923</td>\n",
       "      <td>952.287490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>speechless-mistral-7b</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>950.084667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>codegemma-7b</td>\n",
       "      <td>0.420732</td>\n",
       "      <td>0.113694</td>\n",
       "      <td>947.878057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mixtral-8x7b-instruct</td>\n",
       "      <td>0.408537</td>\n",
       "      <td>0.090828</td>\n",
       "      <td>943.452771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>solar-10.7b-instruct</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.070757</td>\n",
       "      <td>932.310678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mistralai--Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.069868</td>\n",
       "      <td>927.818351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gemma-1.1-7b-it</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.058308</td>\n",
       "      <td>925.563807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>code-llama-multi-13b</td>\n",
       "      <td>0.347561</td>\n",
       "      <td>0.061230</td>\n",
       "      <td>921.036952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>octocoder</td>\n",
       "      <td>0.335366</td>\n",
       "      <td>0.064405</td>\n",
       "      <td>916.485028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>xdan-l1-chat</td>\n",
       "      <td>0.329268</td>\n",
       "      <td>0.059197</td>\n",
       "      <td>914.199134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>python-code-13b</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.057419</td>\n",
       "      <td>909.606390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model     pass1  win_rate          elo\n",
       "4                  claude-3-opus-20240229  0.774390  0.252795  1074.682237\n",
       "17            deepseek-coder-33b-instruct  0.762195  0.241489  1070.180987\n",
       "32             opencodeinterpreter-ds-33b  0.743902  0.238313  1063.469311\n",
       "27            mixtral-8x22b-instruct-v0.1  0.737805  0.233740  1061.242032\n",
       "37               speechless-codellama-34b  0.725610  0.219893  1056.801266\n",
       "0       HuggingFaceH4--starchat2-15b-v0.1  0.719512  0.219258  1054.587410\n",
       "11                    code-millenials-34b  0.719512  0.222815  1054.587410\n",
       "18           deepseek-coder-6.7b-instruct  0.719512  0.232342  1054.587410\n",
       "22              meta-llama-3-70b-instruct  0.719512  0.219385  1054.587410\n",
       "19        deepseek-coder-7b-instruct-v1.5  0.713415  0.216336  1052.377664\n",
       "21                          gpt-3.5-turbo  0.707317  0.208333  1050.171848\n",
       "33            opencodeinterpreter-ds-6.7b  0.707317  0.213796  1050.171848\n",
       "48                          xwincoder-34b  0.701220  0.212398  1047.969787\n",
       "3                 claude-3-haiku-20240307  0.689024  0.205030  1043.576224\n",
       "31                               openchat  0.689024  0.205030  1043.576224\n",
       "38               speechless-coder-ds-6.7b  0.664634  0.179116  1034.826534\n",
       "8                 code-llama-70b-instruct  0.664634  0.195884  1034.826534\n",
       "44                white-rabbit-neo-33b-v1  0.658537  0.190168  1032.645924\n",
       "12                          codebooga-34b  0.658537  0.176829  1032.645924\n",
       "5                claude-3-sonnet-20240229  0.646341  0.187500  1028.291714\n",
       "25                   mistral-large-latest  0.634146  0.180767  1023.945755\n",
       "41              speechless-starcoder2-15b  0.634146  0.167937  1023.945755\n",
       "15           deepseek-coder-1.3b-instruct  0.615854  0.162348  1017.439446\n",
       "2   bigcode--starcoder2-15b-instruct-v0.1  0.609756  0.157774  1015.273398\n",
       "1                  Qwen--Qwen1.5-72B-Chat  0.597561  0.158283  1010.944426\n",
       "23      microsoft--Phi-3-mini-4k-instruct  0.597561  0.160315  1010.944426\n",
       "6                                code-13b  0.536585  0.131479   989.320717\n",
       "14                        codegemma-7b-it  0.530488  0.116997   987.156507\n",
       "39          speechless-coding-7b-16k-tora  0.524390  0.121570   984.991329\n",
       "42               speechless-starcoder2-7b  0.518293  0.118140   982.825021\n",
       "45                        wizardcoder-15b  0.506098  0.110137   978.488381\n",
       "30          open-hermes-2.5-code-290k-13b  0.506098  0.108486   978.488381\n",
       "7                                code-33b  0.500000  0.118140   976.317727\n",
       "34                                  phi-2  0.457317  0.106199   961.064405\n",
       "46                         wizardcoder-7b  0.457317  0.097180   961.064405\n",
       "10                   code-llama-multi-34b  0.439024  0.087779   954.486703\n",
       "16                     deepseek-coder-33b  0.439024  0.105818   954.486703\n",
       "24                  mistral-7b-codealpaca  0.432927  0.094639   952.287490\n",
       "43                     starcoder2-15b-oci  0.432927  0.088923   952.287490\n",
       "40                  speechless-mistral-7b  0.426829  0.078125   950.084667\n",
       "13                           codegemma-7b  0.420732  0.113694   947.878057\n",
       "28                  mixtral-8x7b-instruct  0.408537  0.090828   943.452771\n",
       "36                   solar-10.7b-instruct  0.378049  0.070757   932.310678\n",
       "26    mistralai--Mistral-7B-Instruct-v0.2  0.365854  0.069868   927.818351\n",
       "20                        gemma-1.1-7b-it  0.359756  0.058308   925.563807\n",
       "9                    code-llama-multi-13b  0.347561  0.061230   921.036952\n",
       "29                              octocoder  0.335366  0.064405   916.485028\n",
       "47                           xdan-l1-chat  0.329268  0.059197   914.199134\n",
       "35                        python-code-13b  0.317073  0.057419   909.606390"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "import arena\n",
    "importlib.reload(arena)\n",
    "\n",
    "def subsample(results, n=100):\n",
    "    eids = set(results['example_id'])\n",
    "    include_ids = np.random.choice(list(eids), n, replace=False)\n",
    "    return results[results['example_id'].isin(include_ids)]\n",
    "\n",
    "def sample_table(results):\n",
    "    results = subsample(results, 164)\n",
    "    battles = pass1_to_battle(results)\n",
    "    # battles= battles[battles[\"winner\"].str.contains(\"model_\")]\n",
    "    result_tbl = arena.result_table(battles, results)\n",
    "    return result_tbl\n",
    "\n",
    "for b in ['humaneval+']:\n",
    "    results = eval_results[eval_results['benchmark_id'] == b]\n",
    "    result1 = sample_table(results)\n",
    "    display(result1)\n",
    "    # result2 = sample_table(results)\n",
    "    # result_tblo = result1.merge(result2, on='model', suffixes=['_1', '_2'])\n",
    "    # display(result_tblo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pass1_1</th>\n",
       "      <th>win_rate_1</th>\n",
       "      <th>elo_1</th>\n",
       "      <th>pass1_2</th>\n",
       "      <th>win_rate_2</th>\n",
       "      <th>elo_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pass1_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997382</td>\n",
       "      <td>0.997442</td>\n",
       "      <td>0.974997</td>\n",
       "      <td>0.969106</td>\n",
       "      <td>0.962326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>win_rate_1</th>\n",
       "      <td>0.997382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998887</td>\n",
       "      <td>0.974305</td>\n",
       "      <td>0.974776</td>\n",
       "      <td>0.966176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elo_1</th>\n",
       "      <td>0.997442</td>\n",
       "      <td>0.998887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973309</td>\n",
       "      <td>0.971976</td>\n",
       "      <td>0.965488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pass1_2</th>\n",
       "      <td>0.974997</td>\n",
       "      <td>0.974305</td>\n",
       "      <td>0.973309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994639</td>\n",
       "      <td>0.994762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>win_rate_2</th>\n",
       "      <td>0.969106</td>\n",
       "      <td>0.974776</td>\n",
       "      <td>0.971976</td>\n",
       "      <td>0.994639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elo_2</th>\n",
       "      <td>0.962326</td>\n",
       "      <td>0.966176</td>\n",
       "      <td>0.965488</td>\n",
       "      <td>0.994762</td>\n",
       "      <td>0.997025</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pass1_1  win_rate_1     elo_1   pass1_2  win_rate_2     elo_2\n",
       "pass1_1     1.000000    0.997382  0.997442  0.974997    0.969106  0.962326\n",
       "win_rate_1  0.997382    1.000000  0.998887  0.974305    0.974776  0.966176\n",
       "elo_1       0.997442    0.998887  1.000000  0.973309    0.971976  0.965488\n",
       "pass1_2     0.974997    0.974305  0.973309  1.000000    0.994639  0.994762\n",
       "win_rate_2  0.969106    0.974776  0.971976  0.994639    1.000000  0.997025\n",
       "elo_2       0.962326    0.966176  0.965488  0.994762    0.997025  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass1_1 pass1_1 1.0\n",
      "pass1_1 win_rate_1 0.9755612440507009\n",
      "pass1_1 elo_1 0.9721231427500816\n",
      "pass1_1 pass1_2 0.8849327799071217\n",
      "pass1_1 win_rate_2 0.8569467491793381\n",
      "pass1_1 elo_2 0.8586657998296476\n",
      "win_rate_1 pass1_1 0.9755612440507009\n",
      "win_rate_1 win_rate_1 0.9999999999999998\n",
      "win_rate_1 elo_1 0.9965986394557822\n",
      "win_rate_1 pass1_2 0.8797718387651441\n",
      "win_rate_1 win_rate_2 0.8554421768707482\n",
      "win_rate_1 elo_2 0.857142857142857\n",
      "elo_1 pass1_1 0.9721231427500816\n",
      "elo_1 win_rate_1 0.9965986394557822\n",
      "elo_1 elo_1 0.9999999999999998\n",
      "elo_1 pass1_2 0.8797718387651441\n",
      "elo_1 win_rate_2 0.8554421768707482\n",
      "elo_1 elo_2 0.857142857142857\n",
      "pass1_2 pass1_1 0.8849327799071218\n",
      "pass1_2 win_rate_1 0.8797718387651441\n",
      "pass1_2 elo_1 0.8797718387651441\n",
      "pass1_2 pass1_2 1.0\n",
      "pass1_2 win_rate_2 0.9708419705123171\n",
      "pass1_2 elo_2 0.9691236661397291\n",
      "win_rate_2 pass1_1 0.8569467491793381\n",
      "win_rate_2 win_rate_1 0.8554421768707482\n",
      "win_rate_2 elo_1 0.8554421768707482\n",
      "win_rate_2 pass1_2 0.9708419705123171\n",
      "win_rate_2 win_rate_2 0.9999999999999998\n",
      "win_rate_2 elo_2 0.9948979591836733\n",
      "elo_2 pass1_1 0.8586657998296476\n",
      "elo_2 win_rate_1 0.857142857142857\n",
      "elo_2 elo_1 0.857142857142857\n",
      "elo_2 pass1_2 0.9691236661397291\n",
      "elo_2 win_rate_2 0.9948979591836733\n",
      "elo_2 elo_2 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "result_tbl = result_tblo.set_index('model')\n",
    "display(result_tbl.corr())\n",
    "for v1 in result_tbl.columns:\n",
    "    for v2 in result_tbl.columns:\n",
    "        kt = stats.kendalltau(result_tbl[v1], result_tbl[v2])\n",
    "        print(v1, v2, kt.statistic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import dblquad\n",
    "from scipy.special import gamma\n",
    "\n",
    "def beta_n(x, ax, bx):\n",
    "    return gamma(ax + bx) / gamma(ax) / gamma(bx) * x**(ax-1) * (1-x)**(bx-1) \n",
    "def beta_coef(y, x, ax, bx, ay, by):\n",
    "    return beta_n(x, ax, bx) * beta_n(y, ay, by)\n",
    "def beta(y, x):\n",
    "    return beta_coef(y, x, 10, 10, 11, 9)\n",
    "\n",
    "dblquad(beta, 0, 1, 0, lambda x: x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ps = 0.1 * np.random.rand(10, 1)\n",
    "scores = []\n",
    "num_noties = []\n",
    "for _ in range(10000):\n",
    "    match_notie = np.random.rand(*ps.shape) < ps\n",
    "    num_noties.append(match_notie.sum())\n",
    "\n",
    "    signs = np.sign(np.random.randn(*ps.shape))[match_notie > 0]\n",
    "    s = signs.sum()\n",
    "    scores.append(s)\n",
    "\n",
    "plt.hist(scores, bins=50)\n",
    "plt.figure()\n",
    "plt.hist(num_noties, bins=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install py-irt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/nd-ball/py-irt/d2a27dd55a84459782a5514e752ee48d9a63626e/test_fixtures/minitest.jsonlines\n",
    "!cat minitest.jsonlines\n",
    "\n",
    "!py-irt train 1pl minitest.jsonlines test-1pl/ --lr 0.02 --epochs 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arena\n",
    "import importlib\n",
    "importlib.reload(arena)\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rng\n",
    "\n",
    "tie_probs = np.concatenate((1 - 0.05 * np.random.rand(100), 0*np.random.rand(100)))\n",
    "weights = rng.rand(tie_probs.size)\n",
    "# print(tie_probs)\n",
    "\n",
    "samps = []\n",
    "for _ in range(1000):\n",
    "    p = tie_probs.size\n",
    "    response_a = (rng.rand(p) > tie_probs) * np.sign(rng.randn(p))\n",
    "    response_b = response_a * -1\n",
    "    response_b = np.sign(rng.randn(p))\n",
    "    cdf, pvalue = arena.sign_test_niid(response_a, response_b, weights, tie_probs)\n",
    "    samps.append(pvalue)\n",
    "\n",
    "plt.hist(samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cdf)\n",
    "ax = plt.subplot()\n",
    "cdf.plot(ax)\n",
    "print(cdf.evaluate(-0.1))\n",
    "print(cdf.evaluate(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arena\n",
    "import importlib\n",
    "importlib.reload(arena)\n",
    "def trinomial(na, nb, n0):\n",
    "    n = na + nb + n0\n",
    "    cdf, pvalue = arena.sign_test_niid(([1]*na + [0]*nb + [0]*n0), np.array([0]*na + [1]*nb + [0]*n0), tie_probs=None, weights=None, sample_all=False)\n",
    "    cdf, pvalue = arena.sign_test_niid(np.array([1]*na + [0]*nb + [0]*n0), np.array([0]*na + [1]*nb + [0]*n0), tie_probs=n0 / n * np.array([1] * n), weights=None, sample_all=True)\n",
    "    print('binom', stats.binomtest(na, na + nb, p=0.5).pvalue)\n",
    "    return pvalue\n",
    "\n",
    "# trinomial(20, 12, 133)\n",
    "\n",
    "def bootstrap_consistency(battles: pd.Series, num_round=1000, interpolation='nearest'):\n",
    "    rows = []\n",
    "    counts = Counter(battles)\n",
    "    sign = np.sign(counts['model_a'] - counts['model_b'])\n",
    "    for i in range(num_round):\n",
    "        counts = Counter(battles.sample(frac=1.0, replace=True))\n",
    "        diff = counts['model_a'] - counts['model_b']\n",
    "        rows.append(diff)\n",
    "    return 1 - np.mean(np.sign(rows) == sign)\n",
    "\n",
    "\n",
    "\n",
    "print(bootstrap_ci(pd.Series(['model_a', 'model_b', 'model_a', 'both']*2)))\n",
    "    \n",
    "thres = stats.chi2.ppf(1-0.1, 1)\n",
    "print(thres, np.mean(np.random.randn(100000)**2 > thres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.binomtest(61, 100, p=0.5).pvalue)\n",
    "print(stats.binomtest(61, 100, p=0.5, alternative='greater').pvalue * 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codegen_240116_sida",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
