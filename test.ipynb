{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, math, glob\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import arena\n",
    "\n",
    "records = []\n",
    "for fname in glob.glob(f\"data/*.jsonl\"):\n",
    "    with open(fname, 'rt') as f:\n",
    "        records.extend([json.loads(l) for l in f.readlines()])\n",
    "eval_results = pd.DataFrame(records)\n",
    "\n",
    "benchmarks = set(eval_results['benchmark_id'])\n",
    "records = []\n",
    "for b in benchmarks:\n",
    "    result = eval_results[eval_results['benchmark_id'] == b] \n",
    "    battles = arena.pass1_to_battle(result)\n",
    "    summary = arena.battle_summary(battles)\n",
    "    agg_results = arena.result_table(battles, result)\n",
    "    ex = arena.example_table(result, agg_results)\n",
    "\n",
    "    data_sz = int(summary.iloc[0]['total'])\n",
    "    num_tested = len(set(result['model']))\n",
    "    min_p5 = int(summary[summary['pvalue'] < 0.05]['diff'].abs().min())\n",
    "    max_p5 = int(summary[summary['pvalue'] > 0.05]['diff'].abs().max())\n",
    "    min_dist = int(summary['sum'].abs().min())\n",
    "    print(f'{b}\\t N={data_sz},\\t diff_min/max={min_p5}/{max_p5}')\n",
    "    r = {\n",
    "        'benchmark_id': b,\n",
    "        'size': data_sz,\n",
    "        # 'models_tested': num_tested,\n",
    "        'p5_min': min_p5,\n",
    "        'p5_max': max_p5,\n",
    "        'min_dist': min_dist,\n",
    "        'no_solve': (ex['acc'] == 0).to_numpy().sum(),\n",
    "        # '#solved_by_1': ((ex['acc'] > 0) & (ex['acc'] <= 1/num_tested+ 1e-10)).to_numpy().sum(),\n",
    "        'neg_tau': (ex['tau'] < 0).to_numpy().sum(),\n",
    "    }\n",
    "    display(r)\n",
    "    records.append(r)\n",
    "\n",
    "summary_counts = pd.DataFrame(records).sort_values(by='benchmark_id')\n",
    "display(summary_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>benchmark_id</th>\n",
       "      <th>size</th>\n",
       "      <th>p5_min</th>\n",
       "      <th>p5_max</th>\n",
       "      <th>min_dist</th>\n",
       "      <th>no_solve</th>\n",
       "      <th>neg_tau</th>\n",
       "      <th>link to details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRUXEval-input</td>\n",
       "      <td>800</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.038750</td>\n",
       "      <td>79</td>\n",
       "      <td>0.023750</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>by &lt;a href=\"model_CRUXEval-input.html\"&gt;models ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CRUXEval-output</td>\n",
       "      <td>800</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>67</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.061250</td>\n",
       "      <td>by &lt;a href=\"model_CRUXEval-output.html\"&gt;models...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DS1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>74</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>by &lt;a href=\"model_DS1000.html\"&gt;models &lt;/a&gt; | &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>humaneval</td>\n",
       "      <td>164</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>20</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.018293</td>\n",
       "      <td>by &lt;a href=\"model_humaneval.html\"&gt;models &lt;/a&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>humaneval+</td>\n",
       "      <td>164</td>\n",
       "      <td>0.067073</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>23</td>\n",
       "      <td>0.042683</td>\n",
       "      <td>0.018293</td>\n",
       "      <td>by &lt;a href=\"model_humaneval+.html\"&gt;models &lt;/a&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lcb_codegen</td>\n",
       "      <td>400</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>27</td>\n",
       "      <td>0.242500</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>by &lt;a href=\"model_lcb_codegen.html\"&gt;models &lt;/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mbpp</td>\n",
       "      <td>378</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.058201</td>\n",
       "      <td>38</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.039683</td>\n",
       "      <td>by &lt;a href=\"model_mbpp.html\"&gt;models &lt;/a&gt; | &lt;a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mbpp+</td>\n",
       "      <td>378</td>\n",
       "      <td>0.042328</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>40</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.058201</td>\n",
       "      <td>by &lt;a href=\"model_mbpp+.html\"&gt;models &lt;/a&gt; | &lt;a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      benchmark_id  size    p5_min    p5_max  min_dist  no_solve   neg_tau  \\\n",
       "0   CRUXEval-input   800  0.031250  0.038750        79  0.023750  0.093750   \n",
       "1  CRUXEval-output   800  0.031250  0.032500        67  0.035000  0.061250   \n",
       "4           DS1000  1000  0.021000  0.032000        74  0.159000  0.039000   \n",
       "7        humaneval   164  0.060976  0.097561        20  0.036585  0.018293   \n",
       "3       humaneval+   164  0.067073  0.097561        23  0.042683  0.018293   \n",
       "2      lcb_codegen   400  0.032500  0.047500        27  0.242500  0.015000   \n",
       "5             mbpp   378  0.037037  0.058201        38  0.023810  0.039683   \n",
       "6            mbpp+   378  0.042328  0.055556        40  0.095238  0.058201   \n",
       "\n",
       "                                     link to details  \n",
       "0  by <a href=\"model_CRUXEval-input.html\">models ...  \n",
       "1  by <a href=\"model_CRUXEval-output.html\">models...  \n",
       "4  by <a href=\"model_DS1000.html\">models </a> | <...  \n",
       "7  by <a href=\"model_humaneval.html\">models </a> ...  \n",
       "3  by <a href=\"model_humaneval+.html\">models </a>...  \n",
       "2  by <a href=\"model_lcb_codegen.html\">models </a...  \n",
       "5  by <a href=\"model_mbpp.html\">models </a> | <a ...  \n",
       "6  by <a href=\"model_mbpp+.html\">models </a> | <a...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_count = pd.DataFrame(records).sort_values(by='benchmark_id')\n",
    "def links(b):\n",
    "    l1 = f\"\"\"by <a href=\"model_{b}.html\">models </a> | \"\"\"\n",
    "    l2 = f\"\"\"<a href=\"ex_{b}.html\"> examples </a>\"\"\"\n",
    "    return l1 + l2\n",
    "summary_count['link to details'] = summary_count['benchmark_id'].apply(links)\n",
    "\n",
    "def normalize(counts, includes):\n",
    "    percent = pd.DataFrame(counts)\n",
    "    for c in includes:\n",
    "        percent[c] = percent[c] / percent['size']\n",
    "    return percent\n",
    "\n",
    "includes_cols = ['benchmark_id', 'size', 'p5_min', 'p5_max', 'no_solve', 'neg_tau', 'link to details']\n",
    "percent_cols = ['p5_min', 'p5_max', 'no_solve', 'neg_tau']\n",
    "summary_percent = normalize(summary_count, percent_cols)\n",
    "display(summary_percent)\n",
    "\n",
    "from jinja2 import Template\n",
    "template_path = r\"summary.html\"\n",
    "output_path = rf\"crux-eval.github.io/eval-arena/index.html\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    with open(template_path) as template_file:\n",
    "        j2_template = Template(template_file.read())\n",
    "        output_file.write(j2_template.render({\n",
    "            'count_table': summary_count[includes_cols].to_html(escape=False, index=False),\n",
    "            'percent_table': summary_percent[includes_cols].to_html(\n",
    "                escape=False,\n",
    "                index=False,\n",
    "                formatters={\n",
    "                    'p5_min': '{:.1%}'.format,\n",
    "                    'p5_max': '{:.1%}'.format,\n",
    "                    'min_dist': '{:.1%}'.format,\n",
    "                    'no_solve': '{:.1%}'.format,\n",
    "                    'neg_tau': '{:.1%}'.format,\n",
    "                }),\n",
    "        }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = set(eval_results['benchmark_id'])\n",
    "pairs = {}\n",
    "pairs['humaneval'] = pairs['humaneval+'] = [\n",
    "    ('claude-3-sonnet-20240229', 'claude-3-haiku-20240307'),\n",
    "    ('claude-3-opus-20240229', 'claude-3-sonnet-20240229'),\n",
    "    ('code-llama-multi-34b', 'code-llama-multi-13b'),\n",
    "    ('wizardcoder-34b', 'wizardcoder-15b'),\n",
    "]\n",
    "pairs['mbpp'] = pairs['mbpp+'] = pairs['humaneval']\n",
    "pairs['CRUXEval-input'] = pairs['CRUXEval-output'] = [\n",
    "    ('deepseek-base-33b', 'deepseek-base-6.7b'),\n",
    "    ('deepseek-instruct-33b', 'deepseek-instruct-6.7b'),\n",
    "    ('codellama-34b', 'codellama-13b'),\n",
    "    ('codellama-13b', 'codellama-7b')\n",
    "]\n",
    "\n",
    "def subsample(results, n=100):\n",
    "    eids = set(results['example_id'])\n",
    "    include_ids = np.random.choice(list(eids), n, replace=False)\n",
    "    return results[results['example_id'].isin(include_ids)]\n",
    "\n",
    "def sample_table(results):\n",
    "    results = subsample(results, 164)\n",
    "    battles = pass1_to_battle(results)\n",
    "    # battles= battles[battles[\"winner\"].str.contains(\"model_\")]\n",
    "    result_tbl = arena.result_table(battles, results)\n",
    "    return result_tbl\n",
    "\n",
    "for b in [humaneval+']:\n",
    "    results = eval_results[eval_results['benchmark_id'] == b]\n",
    "    result1 = sample_table(results)\n",
    "    display(result1)\n",
    "    # result2 = sample_table(results)\n",
    "    # result_tblo = result1.merge(result2, on='model', suffixes=['_1', '_2'])\n",
    "    # display(result_tblo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_diff</th>\n",
       "      <th>acc_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CohereForAI--c4ai-command-r-plus</th>\n",
       "      <td>0.0</td>\n",
       "      <td>144.216931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuggingFaceH4--starchat2-15b-v0.1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>142.248677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen--Qwen1.5-72B-Chat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>150.772487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigcode--starcoder2-15b-instruct-v0.1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>129.550265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-haiku-20240307</th>\n",
       "      <td>0.0</td>\n",
       "      <td>120.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <td>0.0</td>\n",
       "      <td>71.534392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-sonnet-20240229</th>\n",
       "      <td>0.0</td>\n",
       "      <td>103.661376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code-llama-13b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>175.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code-llama-34b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>160.804233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code-llama-multi-13b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>176.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code-llama-multi-34b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code-llama-multi-7b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>187.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code-millenials-34b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>137.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegemma-2b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>186.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegemma-7b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>171.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegemma-7b-it</th>\n",
       "      <td>0.0</td>\n",
       "      <td>157.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegen-16b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>187.645503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegen-2b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>187.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codegen-6b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>188.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codet5p-16b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>185.693122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codet5p-2b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>188.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codet5p-6b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>188.359788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>databricks--dbrx-instruct</th>\n",
       "      <td>0.0</td>\n",
       "      <td>166.645503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-coder-33b-instruct</th>\n",
       "      <td>0.0</td>\n",
       "      <td>119.026455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-coder-6.7b-base</th>\n",
       "      <td>0.0</td>\n",
       "      <td>152.550265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-coder-6.7b-instruct</th>\n",
       "      <td>0.0</td>\n",
       "      <td>142.248677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dolphin-2.6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>156.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.0</td>\n",
       "      <td>185.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-2b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>183.915344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>188.470899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-7b-it</th>\n",
       "      <td>0.0</td>\n",
       "      <td>180.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-1106-preview</th>\n",
       "      <td>0.0</td>\n",
       "      <td>92.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama-3-70b-instruct</th>\n",
       "      <td>0.0</td>\n",
       "      <td>110.248677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft--Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.0</td>\n",
       "      <td>169.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral-7b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>188.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral-large-latest</th>\n",
       "      <td>0.0</td>\n",
       "      <td>149.867725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai--Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>186.883598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixtral-8x22b-instruct-v0.1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>146.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixtral-8x7b-instruct</th>\n",
       "      <td>0.0</td>\n",
       "      <td>182.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>octocoder</th>\n",
       "      <td>0.0</td>\n",
       "      <td>182.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open-hermes-2.5-code-290k-13b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>188.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openchat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>174.693122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opencodeinterpreter-ds-33b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>120.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opencodeinterpreter-ds-6.7b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>136.089947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phi-2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>174.137566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solar-10.7b-instruct</th>\n",
       "      <td>0.0</td>\n",
       "      <td>186.201058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speechless-codellama-34b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>146.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speechless-mistral-7b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>184.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speechless-starcoder2-15b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>147.089947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speechless-starcoder2-7b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stable-code-3b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>187.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-15b-oci</th>\n",
       "      <td>0.0</td>\n",
       "      <td>144.216931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-3b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>188.105820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white-rabbit-neo-33b-v1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>123.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wizardcoder-15b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>173.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wizardcoder-34b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>141.248677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wizardcoder-7b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>183.582011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xdan-l1-chat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>188.994709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xwincoder-34b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>133.952381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       true_diff     acc_std\n",
       "model                                                       \n",
       "CohereForAI--c4ai-command-r-plus             0.0  144.216931\n",
       "HuggingFaceH4--starchat2-15b-v0.1            0.0  142.248677\n",
       "Qwen--Qwen1.5-72B-Chat                       0.0  150.772487\n",
       "bigcode--starcoder2-15b-instruct-v0.1        0.0  129.550265\n",
       "claude-3-haiku-20240307                      0.0  120.238095\n",
       "claude-3-opus-20240229                       0.0   71.534392\n",
       "claude-3-sonnet-20240229                     0.0  103.661376\n",
       "code-llama-13b                               0.0  175.238095\n",
       "code-llama-34b                               0.0  160.804233\n",
       "code-llama-multi-13b                         0.0  176.296296\n",
       "code-llama-multi-34b                         0.0  168.000000\n",
       "code-llama-multi-7b                          0.0  187.962963\n",
       "code-millenials-34b                          0.0  137.142857\n",
       "codegemma-2b                                 0.0  186.666667\n",
       "codegemma-7b                                 0.0  171.809524\n",
       "codegemma-7b-it                              0.0  157.629630\n",
       "codegen-16b                                  0.0  187.645503\n",
       "codegen-2b                                   0.0  187.962963\n",
       "codegen-6b                                   0.0  188.952381\n",
       "codet5p-16b                                  0.0  185.693122\n",
       "codet5p-2b                                   0.0  188.809524\n",
       "codet5p-6b                                   0.0  188.359788\n",
       "databricks--dbrx-instruct                    0.0  166.645503\n",
       "deepseek-coder-33b-instruct                  0.0  119.026455\n",
       "deepseek-coder-6.7b-base                     0.0  152.550265\n",
       "deepseek-coder-6.7b-instruct                 0.0  142.248677\n",
       "dolphin-2.6                                  0.0  156.809524\n",
       "gemma-1.1-7b-it                              0.0  185.142857\n",
       "gemma-2b                                     0.0  183.915344\n",
       "gemma-7b                                     0.0  188.470899\n",
       "gemma-7b-it                                  0.0  180.952381\n",
       "gpt-4-1106-preview                           0.0   92.571429\n",
       "meta-llama-3-70b-instruct                    0.0  110.248677\n",
       "microsoft--Phi-3-mini-4k-instruct            0.0  169.952381\n",
       "mistral-7b                                   0.0  188.740741\n",
       "mistral-large-latest                         0.0  149.867725\n",
       "mistralai--Mistral-7B-Instruct-v0.2          0.0  186.883598\n",
       "mixtral-8x22b-instruct-v0.1                  0.0  146.142857\n",
       "mixtral-8x7b-instruct                        0.0  182.142857\n",
       "octocoder                                    0.0  182.518519\n",
       "open-hermes-2.5-code-290k-13b                0.0  188.571429\n",
       "openchat                                     0.0  174.693122\n",
       "opencodeinterpreter-ds-33b                   0.0  120.238095\n",
       "opencodeinterpreter-ds-6.7b                  0.0  136.089947\n",
       "phi-2                                        0.0  174.137566\n",
       "solar-10.7b-instruct                         0.0  186.201058\n",
       "speechless-codellama-34b                     0.0  146.142857\n",
       "speechless-mistral-7b                        0.0  184.851852\n",
       "speechless-starcoder2-15b                    0.0  147.089947\n",
       "speechless-starcoder2-7b                     0.0  168.000000\n",
       "stable-code-3b                               0.0  187.285714\n",
       "starcoder2-15b-oci                           0.0  144.216931\n",
       "starcoder2-3b                                0.0  188.105820\n",
       "white-rabbit-neo-33b-v1                      0.0  123.809524\n",
       "wizardcoder-15b                              0.0  173.571429\n",
       "wizardcoder-34b                              0.0  141.248677\n",
       "wizardcoder-7b                               0.0  183.582011\n",
       "xdan-l1-chat                                 0.0  188.994709\n",
       "xwincoder-34b                                0.0  133.952381"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>models</th>\n",
       "      <th>acc</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mbpp/579</td>\n",
       "      <td>[code-llama-multi-7b, databricks--dbrx-instruc...</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.146907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mbpp/127</td>\n",
       "      <td>[databricks--dbrx-instruct, CohereForAI--c4ai-...</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.267697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mbpp/792</td>\n",
       "      <td>[code-llama-multi-7b, CohereForAI--c4ai-comman...</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.168112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mbpp/269</td>\n",
       "      <td>[code-llama-multi-7b, databricks--dbrx-instruc...</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.208615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mbpp/554</td>\n",
       "      <td>[CohereForAI--c4ai-command-r-plus, claude-3-ha...</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.014826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Mbpp/594</td>\n",
       "      <td>[databricks--dbrx-instruct, CohereForAI--c4ai-...</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.426841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Mbpp/80</td>\n",
       "      <td>[databricks--dbrx-instruct, CohereForAI--c4ai-...</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.500586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Mbpp/725</td>\n",
       "      <td>[CohereForAI--c4ai-command-r-plus, claude-3-ha...</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.403599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>Mbpp/119</td>\n",
       "      <td>[CohereForAI--c4ai-command-r-plus, claude-3-ha...</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>0.305740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Mbpp/639</td>\n",
       "      <td>[code-llama-multi-7b, databricks--dbrx-instruc...</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.009060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    example_id                                             models       acc  \\\n",
       "0     Mbpp/579  [code-llama-multi-7b, databricks--dbrx-instruc...  0.932203   \n",
       "1     Mbpp/127  [databricks--dbrx-instruct, CohereForAI--c4ai-...  0.932203   \n",
       "2     Mbpp/792  [code-llama-multi-7b, CohereForAI--c4ai-comman...  0.949153   \n",
       "3     Mbpp/269  [code-llama-multi-7b, databricks--dbrx-instruc...  0.966102   \n",
       "4     Mbpp/554  [CohereForAI--c4ai-command-r-plus, claude-3-ha...  0.542373   \n",
       "..         ...                                                ...       ...   \n",
       "373   Mbpp/594  [databricks--dbrx-instruct, CohereForAI--c4ai-...  0.627119   \n",
       "374    Mbpp/80  [databricks--dbrx-instruct, CohereForAI--c4ai-...  0.677966   \n",
       "375   Mbpp/725  [CohereForAI--c4ai-command-r-plus, claude-3-ha...  0.457627   \n",
       "376   Mbpp/119  [CohereForAI--c4ai-command-r-plus, claude-3-ha...  0.406780   \n",
       "377   Mbpp/639  [code-llama-multi-7b, databricks--dbrx-instruc...  0.542373   \n",
       "\n",
       "          tau  \n",
       "0    0.146907  \n",
       "1    0.267697  \n",
       "2    0.168112  \n",
       "3    0.208615  \n",
       "4    0.014826  \n",
       "..        ...  \n",
       "373  0.426841  \n",
       "374  0.500586  \n",
       "375  0.403599  \n",
       "376  0.305740  \n",
       "377  0.009060  \n",
       "\n",
       "[378 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example std 7.117312224079408\n"
     ]
    }
   ],
   "source": [
    "def varf(pass1):\n",
    "    p1 = pass1.values\n",
    "    total = len(p1)\n",
    "    return {\n",
    "       'true_diff': 2*np.sum(p1*(1-p1)),\n",
    "       'acc_std': 2 * total * np.mean(p1) * (1-np.mean(p1)), \n",
    "    }\n",
    "\n",
    "for b in ['mbpp']:\n",
    "    result = eval_results[eval_results['benchmark_id'] == b] \n",
    "    battles = arena.pass1_to_battle(result)\n",
    "    agg_results = arena.result_table(battles, result)\n",
    "    summary = result[['model', 'pass1']].groupby('model').aggregate(varf)['pass1'].apply(pd.Series)\n",
    "    ex = arena.example_table(result, agg_results)\n",
    "    display(summary)\n",
    "    display(ex)\n",
    "    p = ex['acc'].values\n",
    "    print('example std', np.sqrt(np.sum(p*(1-p))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import dblquad\n",
    "from scipy.special import gamma\n",
    "\n",
    "def beta_n(x, ax, bx):\n",
    "    return gamma(ax + bx) / gamma(ax) / gamma(bx) * x**(ax-1) * (1-x)**(bx-1) \n",
    "def beta_coef(y, x, ax, bx, ay, by):\n",
    "    return beta_n(x, ax, bx) * beta_n(y, ay, by)\n",
    "def beta(y, x):\n",
    "    return beta_coef(y, x, 10, 10, 11, 9)\n",
    "\n",
    "dblquad(beta, 0, 1, 0, lambda x: x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install py-irt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/nd-ball/py-irt/d2a27dd55a84459782a5514e752ee48d9a63626e/test_fixtures/minitest.jsonlines\n",
    "!cat minitest.jsonlines\n",
    "\n",
    "!py-irt train 1pl minitest.jsonlines test-1pl/ --lr 0.02 --epochs 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arena\n",
    "import importlib\n",
    "importlib.reload(arena)\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rng\n",
    "\n",
    "tie_probs = np.concatenate((1 - 0.05 * np.random.rand(100), 0*np.random.rand(100)))\n",
    "weights = rng.rand(tie_probs.size)\n",
    "# print(tie_probs)\n",
    "\n",
    "samps = []\n",
    "for _ in range(1000):\n",
    "    p = tie_probs.size\n",
    "    response_a = (rng.rand(p) > tie_probs) * np.sign(rng.randn(p))\n",
    "    response_b = response_a * -1\n",
    "    response_b = np.sign(rng.randn(p))\n",
    "    cdf, pvalue = arena.sign_test_niid(response_a, response_b, weights, tie_probs)\n",
    "    samps.append(pvalue)\n",
    "\n",
    "plt.hist(samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cdf)\n",
    "ax = plt.subplot()\n",
    "cdf.plot(ax)\n",
    "print(cdf.evaluate(-0.1))\n",
    "print(cdf.evaluate(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arena\n",
    "import importlib\n",
    "importlib.reload(arena)\n",
    "def trinomial(na, nb, n0):\n",
    "    n = na + nb + n0\n",
    "    cdf, pvalue = arena.sign_test_niid(([1]*na + [0]*nb + [0]*n0), np.array([0]*na + [1]*nb + [0]*n0), tie_probs=None, weights=None, sample_all=False)\n",
    "    cdf, pvalue = arena.sign_test_niid(np.array([1]*na + [0]*nb + [0]*n0), np.array([0]*na + [1]*nb + [0]*n0), tie_probs=n0 / n * np.array([1] * n), weights=None, sample_all=True)\n",
    "    print('binom', stats.binomtest(na, na + nb, p=0.5).pvalue)\n",
    "    return pvalue\n",
    "\n",
    "# trinomial(20, 12, 133)\n",
    "\n",
    "def bootstrap_consistency(battles: pd.Series, num_round=1000, interpolation='nearest'):\n",
    "    rows = []\n",
    "    counts = Counter(battles)\n",
    "    sign = np.sign(counts['model_a'] - counts['model_b'])\n",
    "    for i in range(num_round):\n",
    "        counts = Counter(battles.sample(frac=1.0, replace=True))\n",
    "        diff = counts['model_a'] - counts['model_b']\n",
    "        rows.append(diff)\n",
    "    return 1 - np.mean(np.sign(rows) == sign)\n",
    "\n",
    "\n",
    "\n",
    "print(bootstrap_ci(pd.Series(['model_a', 'model_b', 'model_a', 'both']*2)))\n",
    "    \n",
    "thres = stats.chi2.ppf(1-0.1, 1)\n",
    "print(thres, np.mean(np.random.randn(100000)**2 > thres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_diff_vs_sum(battles):\n",
    "    data_sz = len(set(battles['example_id']))\n",
    "    bmname = set(battles['benchmark_id_a']).pop()\n",
    "\n",
    "    print(data_sz)\n",
    "    def aggfunc(input: pd.Series):\n",
    "        sufs = Counter(input.values) # model_a, model_b, neither, both\n",
    "        res = {} \n",
    "        res['diff'] = sufs['model_a'] - sufs['model_b']\n",
    "        res['sum'] = sufs['model_a'] + sufs['model_b'] \n",
    "        # res['pvalue-chi2'] = 1 if res['diff'] == 0 else (1 - stats.chi2.cdf( (np.abs(res['diff']) - 1)**2 / res['sum'], 1))\n",
    "        res['pvalue'] = stats.binomtest(sufs['model_a'], res['sum'], p=0.5).pvalue\n",
    "        total = sufs.total()\n",
    "        pa = sufs['model_a'] / total\n",
    "        pb = sufs['model_b'] / total\n",
    "        res['std'] = np.sqrt(total * (pa*(1-pa) + pb*(1-pb) + 2*pa*pb))\n",
    "        return res\n",
    "\n",
    "    diffvsum = battles[['model_a', 'model_b', 'winner']]\\\n",
    "        .groupby(['model_a', 'model_b'])\\\n",
    "        .aggregate(aggfunc)\\\n",
    "        ['winner'].apply(pd.Series)\\\n",
    "        .reset_index(drop=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codegen_240116_sida",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
