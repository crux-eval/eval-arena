{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json, glob\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Any, Iterator, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from jinja2 import Template\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "\n",
    "import arena\n",
    "from report_example import gen_example_report\n",
    "from report_model import gen_model_report\n",
    "\n",
    "import importlib\n",
    "importlib.reload(arena)\n",
    "\n",
    "@dataclass\n",
    "class ReportArgs:\n",
    "    out_dir: Optional[str] = 'gh-pages/'\n",
    "    data: str = \"data/*.jsonl\"\n",
    "    recompute: bool = False# generate results for all data and summary line\n",
    "    write_summary: bool = True # use results in out_dir/tmp to generate the summary table\n",
    "\n",
    "def run_arena(args: ReportArgs):\n",
    "    records = []\n",
    "    for fname in glob.glob(args.data):\n",
    "        with open(fname, 'rt') as f:\n",
    "            records.extend([json.loads(l) for l in f.readlines()])\n",
    "    eval_results = pd.DataFrame(records)\n",
    "    display(eval_results)\n",
    "    benchmarks = set(eval_results['benchmark_id'])\n",
    "    print(benchmarks)\n",
    "    return eval_results\n",
    "\n",
    "args = ReportArgs()\n",
    "results = run_arena(args)\n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json, glob\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Any, Iterator, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from jinja2 import Template\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "\n",
    "import arena\n",
    "from report_example import gen_example_report\n",
    "from report_model import gen_model_report, write_summary_table\n",
    "from signal_noise import signal_to_noise\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from jinja2 import Template\n",
    "\n",
    "@dataclass\n",
    "class ReportArgs:\n",
    "    out_dir: Optional[str] = 'gh-pages/'\n",
    "    data: str = \"data/*.jsonl\"\n",
    "    recompute: bool = True # generate results for all data and summary line\n",
    "    write_summary: bool = True # use results in out_dir/tmp to generate the summary table\n",
    "    \n",
    "\n",
    "def run_arena(args: ReportArgs):\n",
    "    tmp_dir = Path(args.out_dir) / 'tmp'\n",
    "    if args.write_summary:\n",
    "        records = []\n",
    "        for fname in glob.glob(f'{tmp_dir}/summary-*.jsonl'):\n",
    "            with open(fname, 'rt') as f:\n",
    "                records.extend([json.loads(l) for l in f.readlines()])\n",
    "        print(records)\n",
    "        # Copy custom.css to the output directory\n",
    "        css_src = Path(\"templates/custom.css\")\n",
    "        css_dst = Path(args.out_dir) / \"static\" / \"custom.css\"\n",
    "        os.makedirs(Path(args.out_dir) / \"static\" , exist_ok=True)\n",
    "        with open(css_src, \"rb\") as src_file, open(css_dst, \"wb\") as dst_file:\n",
    "            dst_file.write(src_file.read())\n",
    "\n",
    "        df_summary = pd.DataFrame(records)\n",
    "        df_summary.to_csv(Path(args.out_dir) / 'summary.csv')\n",
    "        # write_summary_table(pd.DataFrame(df_summary), Path(args.out_dir) / 'index.html')\n",
    "        return df_summary\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ReportArgs:\n",
    "    out_dir: Optional[str] = 'gh-pages/'\n",
    "    data: str = \"data/*.jsonl\"\n",
    "    recompute: bool = False# generate results for all data and summary line\n",
    "    write_summary: bool = True # use results in out_dir/tmp to generate the summary table\n",
    "\n",
    "args = ReportArgs()\n",
    "expanded_results = run_arena(args)\n",
    "# Expand dictionary columns to separate columns\n",
    "\n",
    "# First, let's see what columns contain dictionaries\n",
    "dict_columns = ['std(A)', 'E(std(A))', 'std(A-B)', 'std_signtest', 'corr(A,B)']\n",
    "\n",
    "# Expand each dictionary column\n",
    "for col in dict_columns:\n",
    "    if col in expanded_results.columns:\n",
    "        # Convert string representations to actual dictionaries if needed\n",
    "        dict_data = expanded_results[col].apply(lambda x: x if isinstance(x, dict) else eval(x) if isinstance(x, str) else {})\n",
    "        \n",
    "        # Create new columns for each key in the dictionaries\n",
    "        dict_df = pd.json_normalize(dict_data)\n",
    "        # Rename columns to include the original column name\n",
    "        dict_df.columns = [f\"{col}_{key}\" for key in dict_df.columns]\n",
    "        \n",
    "        # Drop the original dictionary column and concatenate the new columns\n",
    "        expanded_results = expanded_results.drop(columns=[col])\n",
    "        expanded_results = pd.concat([expanded_results, dict_df], axis=1)\n",
    "\n",
    "display(expanded_results)\n",
    "df = expanded_results\n",
    "fig = px.scatter(df, x=\"size\", y=df[\"std(A-B)_mean\"]*np.sqrt(df[\"size\"]), error_y=\"std(A-B)_std\", hover_data=[\"benchmark_id\", \"corr(A,B)_mean\", \"no_solve\", \"tau-\"])\n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.update_yaxes(type=\"log\")\n",
    "display(fig)\n",
    "# Add trend line y = 0.25 / sqrt(x)\n",
    "x_trend = np.logspace(np.log10(df['size'].min()), np.log10(df['size'].max()), 100)\n",
    "y_trend = np.sqrt(0.25 / x_trend)\n",
    "\n",
    "trend_trace = go.Scatter(\n",
    "    x=x_trend, \n",
    "    y=y_trend, \n",
    "    mode='lines',\n",
    "    name='y = 0.25/√x',\n",
    "    line=dict(color='red', dash='dash'),\n",
    "    hovertemplate='Trend: 0.25/√x<extra></extra>'\n",
    ")\n",
    "\n",
    "fig.add_trace(trend_trace)\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Basic box plot from summary statistics\n",
    "fig = go.Figure()\n",
    "# display(df)\n",
    "fig.add_trace(go.Box(\n",
    "    q1=df[\"std(A-B)_25%\"],\n",
    "    q3=df[\"std(A-B)_75%\"],\n",
    "    median=df[\"std(A-B)_50%\"],\n",
    "    mean=df[\"std(A-B)_mean\"],\n",
    "    lowerfence=df[\"std(A-B)_min\"],\n",
    "    upperfence=df[\"std(A-B)_max\"],\n",
    "    x = df[\"size\"],\n",
    "    text=df[\"benchmark_id\"],\n",
    "))\n",
    "display(df[\"size\"])\n",
    "x_trend = np.logspace(np.log10(df['size'].min()), np.log10(df['size'].max()), 100)\n",
    "y_trend = np.sqrt(0.25 / x_trend)\n",
    "\n",
    "trend_trace = go.Scatter(\n",
    "    x=x_trend, \n",
    "    y=y_trend, \n",
    "    mode='lines',\n",
    "    name='y = 0.25/√x',\n",
    "    line=dict(color='red', dash='dash'),\n",
    "    hovertemplate='Trend: 0.25/√x<extra></extra>'\n",
    ")\n",
    "fig.add_trace(trend_trace)\n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from jinja2 import Template\n",
    "\n",
    "import importlib\n",
    "\n",
    "import arena\n",
    "importlib.reload(arena)\n",
    "\n",
    "\n",
    "bid = \"gsm8k\"\n",
    "bid = \"CRUXEval-output-T0.8\"\n",
    "bid = \"mmlu\"\n",
    "bid = \"humaneval+\"\n",
    "bid = \"mmlu\"\n",
    "bid = \"lcb_codegen_v6\"\n",
    "bid = \"mbpp\"\n",
    "bid = \"swebench-verified\"\n",
    "bid = \"mmlu\"\n",
    "selected = results[results[\"benchmark_id\"] == bid]\n",
    "from report_model import fig_accs_and_pvalues\n",
    "\n",
    "def get_sections(result: pd.DataFrame, benchmark_id):\n",
    "    battles = arena.BattleSummary.pass1_to_battle(result)\n",
    "    # display(battles)\n",
    "    summary = arena.BattleSummary.battle_summary(battles)\n",
    "    display(summary)\n",
    "    return summary\n",
    "    \n",
    "# summary = get_sections(selected, bid)\n",
    "\n",
    "# with open(\"gh-pages/temp.html\", \"w\") as fo:\n",
    "#     fo.write(fig.to_html())\n",
    "display(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_df(selected: pd.DataFrame):\n",
    "    marginals = selected.groupby([\"example_id\"]).agg({'pass1': 'mean'}).reset_index().sort_values(by=\"pass1\")\n",
    "    display(marginals)\n",
    "    m1 = marginals[\"pass1\"].to_numpy().copy()\n",
    "    def independent_var(p: np.ndarray, alpha=1) -> float:\n",
    "        \"\"\"\n",
    "        calculate the variance of two independent draws from p, X_i, Y_i ~ Bernoulli(p_i), I want E[(X_i - Y_i)**2]\n",
    "        \"\"\"\n",
    "        N = len(p)\n",
    "        assert np.all(p >= 0) and np.all(p <= 1)\n",
    "        return np.sqrt(1 / N * np.mean(p * (1 - p)))\n",
    "\n",
    "    df = pd.DataFrame({\"alpha\": np.logspace(-5, 5, 1000)})\n",
    "\n",
    "    df[\"p_mean\"] = df[\"alpha\"].map(lambda alpha: np.power(m1, alpha).mean())\n",
    "    df[\"vars\"] = df[\"alpha\"].map(lambda alpha: independent_var(np.power(m1, alpha)))\n",
    "    m2 = np.where((0 < m1) & (m1 < 1), 0.5, m1)\n",
    "    df[\"p_mean_const\"] = df[\"alpha\"].map(lambda alpha: np.power(m2, alpha).mean())\n",
    "    df[\"vars_const\"] = df[\"alpha\"].map(lambda alpha: independent_var(np.power(m2, alpha)))\n",
    "    return df\n",
    "\n",
    "example_means = selected.groupby([\"example_id\"]).agg({'pass1': 'mean'}).reset_index().sort_values(by=\"pass1\")\n",
    "# \n",
    "# fig = px.line(y=m1)\n",
    "m1 = example_means[\"pass1\"].to_numpy().copy()\n",
    "fig = go.Figure()\n",
    "for alpha in []:\n",
    "    fig.add_scatter(y=m1**alpha, mode=\"lines\", name=f'm*{alpha}')\n",
    "\n",
    "# Calculate which models are in top/bottom half based on overall performance\n",
    "model_means = selected.groupby([\"model\"]).agg({'pass1': 'mean'}).reset_index().sort_values(by=\"pass1\")\n",
    "display(model_means)\n",
    "nzs = np.sum(example_means[\"pass1\"] == 0)\n",
    "interval_size = 0.125\n",
    "for start in np.linspace(0, 1, 8):\n",
    "    models = model_means[(model_means[\"pass1\"] >= start) & (model_means[\"pass1\"] < start + interval_size)]\n",
    "    # display(models)\n",
    "    data_inside = selected[selected['model'].isin(models[\"model\"])]\n",
    "    if len(data_inside) == 0:\n",
    "        continue\n",
    "    data_means = data_inside.groupby([\"example_id\"]).agg({'pass1': 'mean'}).reset_index()\n",
    "    # display(data_means, model_means)\n",
    "    # Merge with original marginals to ensure same sorting\n",
    "    data_means_sorted = example_means[['example_id']].merge(data_means, on=\"example_id\", how=\"left\")\n",
    "    data_means_sorted = data_means_sorted.sort_values(\"pass1\")\n",
    "    # wsz = 1\n",
    "    # smoothed = data_means_sorted[\"pass1\"].rolling(window=1, center=True).mean()\n",
    "    smoothed = data_means_sorted[\"pass1\"]\n",
    "    mu = data_means_sorted[\"pass1\"].mean()\n",
    "    n = len(models)\n",
    "    fig.add_scatter(x=smoothed, y=np.arange(len(smoothed))/len(smoothed), name=f\"{start:.2f}-{start+interval_size:.2f} ({n=}, {mu=:.3f})\", mode='lines')\n",
    "\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    alpha = smoothed.mean() / (1 - nzs / len(smoothed)) \n",
    "    beta_param = 1 - alpha\n",
    "    from scipy.stats import beta\n",
    "    s = 1\n",
    "    cdf_values = beta.cdf(x, s*alpha, s*beta_param)\n",
    "\n",
    "    beta_mean = alpha * (1 - nzs / len(smoothed))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x, \n",
    "        y= nzs/len(smoothed) + cdf_values * (1 - nzs/len(smoothed)), \n",
    "        # y= cdf_values * (len(smoothed)), \n",
    "        mode='lines',\n",
    "        name=f'Beta({alpha:.2f}, {beta_param:.2f}) {beta_mean=:.3f}',\n",
    "        line=dict(dash='dash')\n",
    "    ))\n",
    "# Add the first 3 model curves to the plot\n",
    "# for i, (model_name, curve_data) in enumerate(list(model_curves.items())[:10]):\n",
    "#     fig.add_scatter(y=curve_data, name=model_name, mode='lines')\n",
    "fig.update_layout(title=bid)\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_means = selected.groupby([\"model\"]).agg({'pass1': 'mean'}).reset_index().sort_values(by=\"pass1\")\n",
    "# display(model_means)\n",
    "nzs = np.sum(example_means[\"pass1\"] == 0)\n",
    "\n",
    "bottom_models = model_means[:10][\"model\"]\n",
    "top_models = model_means[-10:][\"model\"]\n",
    "mid_models = model_means[-20:-10][\"model\"]\n",
    "\n",
    "\n",
    "def get_mean(models):\n",
    "    data_inside = selected[selected['model'].isin(models)]\n",
    "    data_means = data_inside.groupby([\"example_id\"]).agg({'pass1': 'mean'}).reset_index()\n",
    "    data_means_sorted = example_means[['example_id']].merge(data_means, on=\"example_id\", how=\"left\")\n",
    "    data_means_sorted = data_means_sorted.sort_values(\"pass1\")\n",
    "    return data_means_sorted, data_means_sorted[\"pass1\"].mean()\n",
    "\n",
    "data_means_bot, bot_mean = get_mean(bottom_models)\n",
    "data_means_top, top_mean  = get_mean(top_models)\n",
    "data_means_mid, mid_mean = get_mean(mid_models)\n",
    "\n",
    "\n",
    "# mid_mean = alpha * top_mean + (1-alpha) * bot_mean\n",
    "alpha = (mid_mean - bot_mean) / (top_mean - bot_mean)\n",
    "fig = go.Figure()\n",
    "cdf_bot = stats.ecdf(data_means_bot[\"pass1\"])\n",
    "cdf_top = stats.ecdf(data_means_top[\"pass1\"])\n",
    "fig.add_scatter(x=data_means_bot[\"pass1\"], name=\"bot\")\n",
    "x = np.linspace(0, 1, 1000)\n",
    "fig.add_scatter(x=x, y=len(data_means_top)*cdf_bot.cdf.evaluate(x), name=\"bot_cdf\")\n",
    "print(alpha)\n",
    "fig.add_scatter(x=x, y=beta.cdf(x, alpha, 1-alpha)*len(data_means_bot), name=\"mid_beta\")\n",
    "fig.add_scatter(x=data_means_top[\"pass1\"], name=\"top\")\n",
    "fig.add_scatter(x=data_means_mid[\"pass1\"], name=\"mid_empirical\")\n",
    "mid_paired = alpha*(data_means_top[\"pass1\"]) + (1-alpha)*(data_means_bot[\"pass1\"])\n",
    "mid_unpaired = alpha*(data_means_top[\"pass1\"].to_numpy()) + (1-alpha)*(data_means_bot[\"pass1\"].to_numpy())\n",
    "mid_paired = mid_paired.sort_values()\n",
    "fig.add_scatter(x=mid_unpaired, name=\"mid_unpaired\")\n",
    "fig.add_scatter(x=mid_paired, name=\"mid_paired\")\n",
    "\n",
    "# alpha = 0.5\n",
    "mid_cdf = alpha*(cdf_top.cdf.evaluate(x)) + (1-alpha)*(cdf_bot.cdf.evaluate(x))\n",
    "fig.add_scatter(x=x, y=len(data_means_top)*mid_cdf, name=\"mid_cdf\")\n",
    "print(cdf_bot.cdf.probabilities)\n",
    "def expectation_ecdf_from_steps(cdf, f):\n",
    "    probs = np.diff(np.concatenate(([0.0], cdf.quantiles)))\n",
    "    print(probs)\n",
    "    return np.sum(f(cdf.quantiles) * probs)\n",
    "\n",
    "evar = expectation_ecdf_from_steps(cdf_bot.cdf, lambda x: x*(1-x))\n",
    "print(evar, 0.25*0.75)\n",
    "\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=600,\n",
    "    title=bid\n",
    ")\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fig_cov_baseline(bmname: str, diffvsum: pd.DataFrame, dfmodel):\n",
    "    df = diffvsum\n",
    "    # df[\"is_close\"] = np.where(df[\"sum(A-B)\"].abs() < df[\"total\"] / 20, \"close\", \"not_close\")\n",
    "    df = df[df[\"accA\"] >= df[\"accB\"]]\n",
    "    df[\"is_close\"] = np.where(np.abs(df[\"accA\"] - df[\"accB\"]) / df[\"std(A-B)\"] <= 3, \"close: ≤3σ\", \"not close: >3σ\")\n",
    "    color_map = {\n",
    "        \"close: ≤3σ\": \"blue\",      # Bright red\n",
    "        \"not close: >3σ\": \"#CCCCCC\"     # Light gray\n",
    "    } \n",
    "    figs = px.scatter(df,\n",
    "                    x=np.maximum(df[\"accB\"], df[\"accA\"]), y=\"std(A-B)\",\n",
    "                    color=\"is_close\",\n",
    "                    color_discrete_map=color_map,\n",
    "                    custom_data=[\"model_a\", \"model_b\", \"sum(A!=B)\", \"sum(A-B)\", \"pvalue\", \"std(A-B)\", \"accA\", \"accB\", \"corr(A,B)\"])\n",
    "    figs.for_each_trace(lambda trace: trace.update(opacity=0.5) \n",
    "                   if trace.name == \"not close: >3σ\" else None)\n",
    "    \n",
    "    figs.update_traces(hovertemplate=\n",
    "        \"<br>\".join([\n",
    "        \"Model A: %{customdata[0]} (acc: %{customdata[6]:.1%})\",\n",
    "        \"Model B: %{customdata[1]} (acc: %{customdata[7]:.1%})\", \n",
    "        \"total A≠B: %{customdata[2]:.1f}\",\n",
    "        \"total A-B: %{customdata[3]:.1f}\", \n",
    "        \"std(A-B): %{customdata[5]:.2%}\", \n",
    "        \"p-value: %{customdata[4]:.3g}\",\n",
    "        \"corr(A,B): %{customdata[8]:.3g}\",\n",
    "        ])  + \"<extra></extra>\")\n",
    "\n",
    "    figs.update_traces(\n",
    "        marker=dict(\n",
    "            size=3,\n",
    "            opacity=0.5, \n",
    "        )\n",
    "    )\n",
    "\n",
    "    data_sz = diffvsum.iloc[0][\"total\"]\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    y = np.sqrt(x*(1-x) / data_sz)\n",
    "\n",
    "    figl = go.Figure()\n",
    "\n",
    "    figl.add_trace(go.Scatter(\n",
    "        x=x, y=y, name=\"σ(acc)\",\n",
    "        # hoverinfo=\"skip\",\n",
    "        line=dict(color=\"lightgreen\")\n",
    "    ))\n",
    "\n",
    "    figl.add_trace(go.Scatter(\n",
    "        x=x, y=np.sqrt(2)*y, name=\"sqrt(2) σ(acc)\",\n",
    "        # hoverinfo=\"skip\",\n",
    "        line=dict(color=\"darkgreen\")\n",
    "    ))\n",
    "\n",
    "    figl.add_trace(go.Scatter(\n",
    "        x=dfmodel[\"p_mean\"], y=dfmodel[\"vars\"],\n",
    "        # hoverinfo=\"skip\",\n",
    "        line=dict(color=\"red\"),\n",
    "        name=\"exp\"\n",
    "    ))\n",
    "    figl.add_trace(go.Scatter(\n",
    "        x=dfmodel[\"p_mean_const\"], y=dfmodel[\"vars_const\"],\n",
    "        # hoverinfo=\"skip\",\n",
    "        line=dict(color=\"pink\"),\n",
    "        name=\"vars_const\"\n",
    "    ))\n",
    "\n",
    "    fig = go.Figure(data=figl.data + figs.data)\n",
    "    fig.update_layout(\n",
    "        width=800, height=600, title=bmname,\n",
    "        xaxis_title=\"mean(acc(A), acc(B))\",\n",
    "        yaxis_title=\"σ(A-B)\"\n",
    "    )\n",
    "    return fig\n",
    "display(summary)\n",
    "display(fig_cov_baseline(bid, summary, trend_df(selected)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_stats(s, f=2, percent=True):\n",
    "    return f\"{s['mean']:.2f}±{s['std']:.2f} | [{s['min']:.2f}--{s['max']:.2f}] | n={s['count']} \"\n",
    "\n",
    "def format_stats_badge(s):\n",
    "    s_percent = dict(s)\n",
    "    for st in [\"mean\", \"std\", \"min\", \"max\"]:\n",
    "        s_percent[st] = 100 * s[st]\n",
    "    summary = summary_stats(s_percent)\n",
    "    mean = 100*s[\"mean\"]\n",
    "    return f'<span title=\"{summary}\">{mean:.2f}</span>'\n",
    "\n",
    "def write_summary_table(summary_count: pd.DataFrame, output_path: Path):\n",
    "    summary_count = summary_count.sort_values(by='benchmark_id')\n",
    "\n",
    "    def link_detail(bid):\n",
    "        l1 = f\"\"\"by <a href=\"model_{bid}.html\">models </a> \"\"\"\n",
    "        l2 = f\"\"\"<a href=\"ex_{bid}.html\"> examples </a>\"\"\"\n",
    "        l3 = f\"\"\"<a href=\"ex_v_model_{bid}.html\"> data </a>\"\"\"\n",
    "        return l1 + '|' + l2 + '|' + l3\n",
    "    summary_count['link to details'] = summary_count['benchmark_id'].apply(link_detail)\n",
    "\n",
    "    def normalize(counts, includes):\n",
    "        percent = counts.copy(deep=True)\n",
    "        for c in includes:\n",
    "            percent[c] = percent[c] / percent['size']\n",
    "        return percent\n",
    "\n",
    "    includes_cols = ['benchmark_id', 'size',  'std(A-B)', 'corr_ab', 'p5_min', 'p5_max', 'no_solve', 'tau-', 'sig_noise','link to details']\n",
    "    percent_cols = ['p5_min', 'p5_max', 'no_solve', 'tau-']\n",
    "    summary_percent = normalize(summary_count, percent_cols)\n",
    "\n",
    "    display(summary_percent)\n",
    "    template_path = r\"templates/summary.html\"\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "        with open(template_path) as template_file:\n",
    "            j2_template = Template(template_file.read())\n",
    "            output_file.write(j2_template.render({\n",
    "                'count_table': summary_count[includes_cols].to_html(escape=False, index=False),\n",
    "                'percent_table': summary_percent[includes_cols].to_html(\n",
    "                    escape=False,\n",
    "                    index=False,\n",
    "                    formatters={\n",
    "                        \"std(A-B)\": lambda x: format_stats_badge(x),\n",
    "                        \"corr_ab\": lambda x: format_stats_badge(x),\n",
    "                        'p5_min': lambda x: f'{x*100:.2f}',\n",
    "                        'p5_max': lambda x: f'{x*100:.2f}',\n",
    "                        'min_dist': '{:.2}'.format,\n",
    "                        'no_solve': '{:.2}'.format,\n",
    "                        'tau-': '{:.2}'.format,\n",
    "                        'sig_noise': '{:.2f}'.format,\n",
    "                    }),\n",
    "            }))\n",
    "            \n",
    "def generate_summary(args: ReportArgs):\n",
    "    tmp_dir = Path(args.out_dir) / 'tmp'\n",
    "    os.makedirs(tmp_dir, exist_ok=True)\n",
    "    \n",
    "    if args.write_summary:\n",
    "        records = []\n",
    "        for fname in glob.glob(f'{tmp_dir}/summary-*.jsonl'):\n",
    "            with open(fname, 'rt') as f:\n",
    "                records.extend([json.loads(l) for l in f.readlines()])\n",
    "        print(records)\n",
    "        write_summary_table(pd.DataFrame(records), Path(args.out_dir) / 'index.html')\n",
    "\n",
    "generate_summary(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create a range of alpha values to explore\n",
    "alphas = [0.1, 0.3, 0.5]\n",
    "\n",
    "# Create x values for plotting\n",
    "x = np.linspace(0, 1, 1000)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for alpha in alphas:\n",
    "    # For beta(alpha, 1-alpha), we need alpha > 0 and 1-alpha > 0, so 0 < alpha < 1\n",
    "    if 0 < alpha < 1:\n",
    "        beta_param = 1 - alpha\n",
    "        # Calculate CDF\n",
    "        cdf_values = beta.pdf(x, alpha, beta_param)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, \n",
    "            y=cdf_values, \n",
    "            mode='lines',\n",
    "            name=f'Beta({alpha}, {beta_param:.1f})'\n",
    "        ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Cumulative Distribution Function of Beta(α, 1-α)',\n",
    "    xaxis_title='x',\n",
    "    yaxis_title='CDF(x)',\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in np.linspace(0, 1, 20):\n",
    "    beta_modelpred = beta(2*alpha+1, 2*(1-alpha)+1) / beta(alpha, (1-alpha))\n",
    "    var = alpha * (1-alpha)\n",
    "    print(beta_modelpred, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import beta\n",
    "def plot_betapdf(a=0.5, b=0.5):    \n",
    "    # Define the integrand\n",
    "    def integrand(x):\n",
    "        return x**(a-1) * (1-x)**(b-1) / beta(a, b)\n",
    "\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    return px.scatter(x=x, y=integrand(x))\n",
    "\n",
    "alpha = 0.3\n",
    "fig = plot_betapdf(a=1, b=4)\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import mean, var\n",
    "A = torch.randn([100, 30], dtype=torch.float64) > 0\n",
    "A = A.to(torch.float32)\n",
    "def var(A, dim=None):\n",
    "    return torch.var(A, dim=dim, unbiased=False)\n",
    "# print(A)\n",
    "print(f\"{var(A)=}\")\n",
    "print(f\"{var(A, dim=0)=}\")\n",
    "print(f\"{mean(A)=}\")\n",
    "print(f\"{mean(var(A, dim=0))=}\")\n",
    "print(f\"{var(mean(A, dim=0))=}\")\n",
    "\n",
    "\n",
    "from numpy import mean, var\n",
    "A = A.numpy()\n",
    "print(f\"{var(A)=}\")\n",
    "print(f\"{var(var(A, axis=0))=}\")\n",
    "# print(f\"{var(A, axis=0)=}\")\n",
    "# print(f\"{mean(A)=}\")\n",
    "print(f\"{mean(var(A, axis=0))=}\")\n",
    "print(f\"{var(mean(A, axis=0))=}\")\n",
    "print(f\"{mean(var(A, axis=1))=}\")\n",
    "print(f\"{var(mean(A, axis=1))=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = []\n",
    "N = 5\n",
    "K = 5\n",
    "import numpy as np\n",
    "from numpy import mean, var, std\n",
    "\n",
    "def cov(A, B, ddof=0):\n",
    "    # okay, is there ever a time to need ddof=1?\n",
    "    return np.cov(A, B, ddof=ddof)[0, 1]\n",
    "\n",
    "\n",
    "\n",
    "class Paired:\n",
    "    @staticmethod\n",
    "    def sample_vars(A: np.ndarray, B: np.ndarray, dof=0) -> dict:\n",
    "        assert A.shape[0] == B.shape[0] # paired data\n",
    "        return {\n",
    "            \"var(E(A-B))\": var(mean(A-B, axis=1)),\n",
    "            \"E(var(A-B))\": mean(var(A, axis=1) + var(B, axis=1)),\n",
    "            \"var(A-B)\": var(A) + var(B) - 2 * cov(mean(A, axis=1), mean(B, axis=1)),\n",
    "            # \"_var(A-B)\": mean(A**2 + B**2) - 2 * mean(mean(A, axis=1) * mean(B, axis=1)) - mean(A-B)**2,\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def sample_vars_unbiased(A: np.ndarray, B: np.ndarray, dof=0) -> dict:\n",
    "        assert A.shape[0] == B.shape[0] # paired data\n",
    "        kA = A.shape[1]\n",
    "        kB = A.shape[1]\n",
    "        return {\n",
    "            \"var(E(A-B))\": var(mean(A-B, axis=1)) - mean(var(A, axis=1)/(kA-1) + var(B, axis=1)/(kA-1)) ,\n",
    "            \"E(var(A-B))\": mean(var(A, axis=1)* (1 + 1/(kA-1)) + var(B, axis=1) * (1 + 1/(kB-1))),\n",
    "            \"var(A-B)\": var(A) + var(B) - 2 * cov(mean(A, axis=1), mean(B, axis=1)), # actually this is slightly biased too, but we ignore it\n",
    "            # \"_var(A-B)\": mean(A**2 + B**2) - 2 * mean(mean(A, axis=1) * mean(B, axis=1)) - mean(A-B)**2,\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def bernoulli_sample_vars(A: np.ndarray, B: np.ndarray, dof=0) -> dict:\n",
    "        ...\n",
    "\n",
    "    @staticmethod\n",
    "    def bernoulli_p_vars(pA: np.ndarray, pB: np.ndarray) -> dict:\n",
    "        assert pA.shape[0] == pB.shape[0]\n",
    "        assert pA.shape[1] == pB.shape[1] == 1\n",
    "        pA = pA.flatten()\n",
    "        pB = pB.flatten()\n",
    "        return {\n",
    "            \"var(E(A-B))\": var(pA - pB),\n",
    "            \"E(var(A-B))\": mean(pA*(1-pA) + pB*(1-pB)),\n",
    "            \"var(A-B)\": mean(pA)*(1-mean(pA)) + mean(pB)*(1-mean(pB)) - 2 * cov(pA, pB),\n",
    "            # \"_var(A-B)\": mean(pA + pB - 2*pA*pB) - mean(pA - pB)**2\n",
    "        }\n",
    "\n",
    "\n",
    "pA = np.random.rand(N, 1)\n",
    "pB = (pA + 1*(np.random.rand(N, 1)-0.5)).clip(0, 1)\n",
    "for i in range(10):\n",
    "    A = np.random.rand(N, K)\n",
    "    A = np.where(A < pA, 1, 0)\n",
    "\n",
    "    B = np.random.rand(N, K)\n",
    "    B = np.where(B < pB, 1, 0)\n",
    "\n",
    "    delta = (A-B).mean() \n",
    "    vars = {\n",
    "        \"E(A-B)\": delta,\n",
    "        # \"var(A-B)\":  np.mean(np.mean(A*A + B*B, axis=1) - 2 * A.mean(axis=1) * B.mean(axis=1)) - delta * delta,\n",
    "        # \"var(A-B)\": mean(A*A + B*B) - 2*mean(mean(A, axis=1) * mean(B, axis=1)) - delta * delta,\n",
    "        \n",
    "    }\n",
    "    def total_variance_test(v: dict):\n",
    "        assert np.allclose(v[\"var(A-B)\"], v[\"E(var(A-B))\"] + v[\"var(E(A-B))\"]), v\n",
    "\n",
    "    def relative_error(v1, v2):\n",
    "        # for k in \"var(A-B)\", \"E(var(A-B))\", \"var(E(A-B))\"\n",
    "        ... \n",
    "\n",
    "    v = Paired.sample_vars(A, B)\n",
    "    total_variance_test(v) \n",
    "\n",
    "    vstar = Paired.bernoulli_p_vars(pA, pB)\n",
    "    total_variance_test(vstar)\n",
    "    \n",
    "    v_unb = Paired.sample_vars_unbiased(A, B)\n",
    "    total_variance_test(v_unb) \n",
    "\n",
    "    res.append({\n",
    "        **{(\"star\", k): v for k, v in vstar.items()},\n",
    "        **{(\"hat\", k): v for k, v in v.items()},\n",
    "        **{(\"unb\", k): v for k, v in v_unb.items()},\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(res)\n",
    "# df[\"diff\"] = df[\"var(A-B)\"] - df[\"E(var(A-B))\"] - df[\"var(E(A-B))\"]\n",
    "# df[\"diff2\"] = df[\"_var(A-B)\"] - df[\"E(var(A-B))\"] - df[\"var(E(A-B))\"]\n",
    "# df[\"diff_star\"] = df[\"var(A-B)_star\"] - df[\"E(var(A-B))_star\"] - df[\"var(E(A-B))_star\"]\n",
    "display(df)\n",
    "# px.scatter(df, x=\"x\", y=\"y\")\n",
    "display(df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Single:\n",
    "    @staticmethod\n",
    "    def sample_vars(A: np.ndarray, dof=0) -> dict:\n",
    "        return {\n",
    "            \"var(E(A))\": var(mean(A, axis=1)),\n",
    "            \"E(var(A))\": mean(var(A, axis=1)),\n",
    "            \"var(A)\": var(A),\n",
    "        } \n",
    "    \n",
    "    @staticmethod\n",
    "    def sample_vars_unbiased2(A: np.ndarray) -> dict:\n",
    "        kA = A.shape[1]\n",
    "        N = A.shape[0]\n",
    "        return {\n",
    "            \"var(E(A))\": var(mean(A, axis=1)) - 1/(kA-1) * mean(var(A, axis=1)) + var(A)*1/(N*kA - 1), \n",
    "            \"E(var(A))\": mean(var(A, axis=1, ddof=1)), \n",
    "            \"var(A)\": var(A, ddof=1),  # empirically maybe still < 1% too large  \n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def sample_vars_unbiased(A: np.ndarray) -> dict:\n",
    "        kA = A.shape[1]\n",
    "        N = A.shape[0]\n",
    "        return {\n",
    "            \"var(E(A))\": var(mean(A, axis=1)) - 1/(kA-1) * mean(var(A, axis=1)) + var(A)*1/(N*kA - 1), \n",
    "            \"E(var(A))\": mean(var(A, axis=1)) * (1 + 1/(kA-1)), \n",
    "            \"var(A)\": var(A) * (1 + 1/(N*kA - 1)), # empirically maybe still < 1% too large \n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def bootstrap_SE(A: np.ndarray, boots_size=100) -> dict:\n",
    "        kA = A.shape[1]\n",
    "        N = A.shape[0]\n",
    "        means = []\n",
    "        for _ in range(boots_size):\n",
    "            inds = np.random.choice(N*kA, size=N, replace=True)\n",
    "            samples = A.flatten()[inds]\n",
    "            means.append(samples.mean())\n",
    "\n",
    "        SE = np.std(means)\n",
    "        return {\n",
    "            \"var(A)\": SE**2*N\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def bernoulli_p_vars(pA: np.ndarray) -> dict:\n",
    "        return {\n",
    "            \"var(E(A))\": var(pA),\n",
    "            \"E(var(A))\": mean(pA*(1-pA)),\n",
    "            \"var(A)\": mean(pA)*(1-mean(pA))\n",
    "        }\n",
    "    \n",
    "N, K = 1000, 10\n",
    "pA = np.random.rand(N, 1)\n",
    "# pA = 0.5 * np.ones((N, 1))\n",
    "# pA[:N//2] = 0\n",
    "res = []\n",
    "for i in range(1000):\n",
    "    A = np.random.rand(N, K)\n",
    "    A = np.where(A < pA, 1, 0)\n",
    "    # A = pA + 0.5 * np.random.randn(N, K)\n",
    "\n",
    "    def total_variance_test(v: dict):\n",
    "        assert np.isclose(v[\"var(A)\"], v[\"E(var(A))\"] + v[\"var(E(A))\"]), v\n",
    "\n",
    "    def relative_error(v1, v2):\n",
    "        # for k in \"var(A-B)\", \"E(var(A-B))\", \"var(E(A-B))\"\n",
    "        ... \n",
    "\n",
    "    v = Single.sample_vars(A)\n",
    "    total_variance_test(v) \n",
    "\n",
    "    vstar = Single.bernoulli_p_vars(pA)\n",
    "    total_variance_test(vstar)\n",
    "\n",
    "    v_unb = Single.sample_vars_unbiased(A)\n",
    "    # total_variance_test(v_unb)\n",
    "\n",
    "    v_unb2 = Single.sample_vars_unbiased2(A)\n",
    "    total_variance_test(v_unb2)\n",
    "    for k in v_unb:\n",
    "        assert np.isclose(v_unb[k], v_unb2[k])\n",
    "\n",
    "    se_boots = Single.bootstrap_SE(A, 10)\n",
    "\n",
    "    res.append({\n",
    "        # **{(\"star\", k): v for k, v in vstar.items()},\n",
    "        **{(\"hat\", k): (v - vstar[k]) / vstar[k] for k, v in v.items()},\n",
    "        **{(\"unb\", k): (v - vstar[k]) / vstar[k] for k, v in v_unb.items()},\n",
    "        **{(\"boots\", k): (v - vstar[k]) / vstar[k] for k, v in se_boots.items()},\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(res)\n",
    "# df[\"diff\"] = df[\"var(A-B)\"] - df[\"E(var(A-B))\"] - df[\"var(E(A-B))\"]\n",
    "# df[\"diff2\"] = df[\"_var(A-B)\"] - df[\"E(var(A-B))\"] - df[\"var(E(A-B))\"]\n",
    "# df[\"diff_star\"] = df[\"var(A-B)_star\"] - df[\"E(var(A-B))_star\"] - df[\"var(E(A-B))_star\"]\n",
    "display(df.aggregate(lambda x:\n",
    "                     pd.Series({\n",
    "                         \"std\": std(x),\n",
    "                         \"mse\": np.sqrt(np.mean(x*x)),\n",
    "                         \"mean\": np.mean(x),\n",
    "                    })))\n",
    "# px.scatter(df, x=\"x\", y=\"y\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pA.flatten())\n",
    "print(2 * cov(pA.flatten(), pB.flatten(), ddof=0))\n",
    "print(mean(pA*(1-pA) + pB*(1-pB)))\n",
    "print(var(A))\n",
    "print(pA * (1-pA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.random.randn(10000, 10)\n",
    "print(mean(var(C, axis=1, ddof=1)))\n",
    "print(var(var(C, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array: list[list]\n",
    "token_ids = [t for toks in nested for t in toks]\n",
    "import itertools\n",
    "print(token_ids)\n",
    "print(np.where([0,0,1,1,1,0,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codegen_240613_loc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
